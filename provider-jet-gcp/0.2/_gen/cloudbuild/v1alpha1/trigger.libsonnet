{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='trigger', url='', help='"Trigger is the Schema for the Triggers API"'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of Trigger', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'cloudbuild.gcp.jet.crossplane.io/v1alpha1',
    kind: 'Trigger',
  } + self.metadata.withName(name=name) + self.metadata.withAnnotations(annotations={
    'tanka.dev/namespaced': 'false',
  }),
  '#spec':: d.obj(help='"TriggerSpec defines the desired state of Trigger"'),
  spec: {
    '#forProvider':: d.obj(help=''),
    forProvider: {
      '#build':: d.obj(help='"Contents of the build template. Either a filename or build template must be provided."'),
      build: {
        '#artifacts':: d.obj(help='"Artifacts produced by the build that should be uploaded upon successful completion of all build steps."'),
        artifacts: {
          '#objects':: d.obj(help="\"A list of objects to be uploaded to Cloud Storage upon successful completion of all build steps. \\n Files in the workspace matching specified paths globs will be uploaded to the Cloud Storage location using the builder service account's credentials. \\n The location and generation of the uploaded objects will be stored in the Build resource's results field. \\n If any objects fail to be pushed, the build is marked FAILURE.\""),
          objects: {
            '#withLocation':: d.fn(help='"Cloud Storage bucket and optional object path, in the form \\"gs://bucket/path/to/somewhere/\\". \\n Files in the workspace matching any path pattern will be uploaded to Cloud Storage with this location as a prefix."', args=[d.arg(name='location', type=d.T.string)]),
            withLocation(location): { location: location },
            '#withPaths':: d.fn(help="\"Path globs used to match files in the build's workspace.\"", args=[d.arg(name='paths', type=d.T.array)]),
            withPaths(paths): { paths: if std.isArray(v=paths) then paths else [paths] },
            '#withPathsMixin':: d.fn(help="\"Path globs used to match files in the build's workspace.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='paths', type=d.T.array)]),
            withPathsMixin(paths): { paths+: if std.isArray(v=paths) then paths else [paths] },
          },
          '#withImages':: d.fn(help="\"A list of images to be pushed upon the successful completion of all build steps. \\n The images will be pushed using the builder service account's credentials. \\n The digests of the pushed images will be stored in the Build resource's results field. \\n If any of the images fail to be pushed, the build is marked FAILURE.\"", args=[d.arg(name='images', type=d.T.array)]),
          withImages(images): { images: if std.isArray(v=images) then images else [images] },
          '#withImagesMixin':: d.fn(help="\"A list of images to be pushed upon the successful completion of all build steps. \\n The images will be pushed using the builder service account's credentials. \\n The digests of the pushed images will be stored in the Build resource's results field. \\n If any of the images fail to be pushed, the build is marked FAILURE.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='images', type=d.T.array)]),
          withImagesMixin(images): { images+: if std.isArray(v=images) then images else [images] },
          '#withObjects':: d.fn(help="\"A list of objects to be uploaded to Cloud Storage upon successful completion of all build steps. \\n Files in the workspace matching specified paths globs will be uploaded to the Cloud Storage location using the builder service account's credentials. \\n The location and generation of the uploaded objects will be stored in the Build resource's results field. \\n If any objects fail to be pushed, the build is marked FAILURE.\"", args=[d.arg(name='objects', type=d.T.array)]),
          withObjects(objects): { objects: if std.isArray(v=objects) then objects else [objects] },
          '#withObjectsMixin':: d.fn(help="\"A list of objects to be uploaded to Cloud Storage upon successful completion of all build steps. \\n Files in the workspace matching specified paths globs will be uploaded to the Cloud Storage location using the builder service account's credentials. \\n The location and generation of the uploaded objects will be stored in the Build resource's results field. \\n If any objects fail to be pushed, the build is marked FAILURE.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='objects', type=d.T.array)]),
          withObjectsMixin(objects): { objects+: if std.isArray(v=objects) then objects else [objects] },
        },
        '#options':: d.obj(help='"Special options for this build."'),
        options: {
          '#volumes':: d.obj(help='"Global list of volumes to mount for ALL build steps \\n Each volume is created as an empty volume prior to starting the build process. Upon completion of the build, volumes and their contents are discarded. Global volume names and paths cannot conflict with the volumes defined a build step. \\n Using a global volume in a build with only one step is not valid as it is indicative of a build request with an incorrect configuration."'),
          volumes: {
            '#withName':: d.fn(help='"Name of the volume to mount. \\n Volume names must be unique per build step and must be valid names for Docker volumes. Each named volume must be used by at least two build steps."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withPath':: d.fn(help='"Path at which to mount the volume. \\n Paths must be absolute and cannot conflict with other volume paths on the same build step or with certain reserved volume paths."', args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { path: path },
          },
          '#withDiskSizeGb':: d.fn(help='"Requested disk size for the VM that runs the build. Note that this is NOT \\"disk free\\"; some of the space will be used by the operating system and build utilities. Also note that this is the minimum disk size that will be allocated for the build -- the build may run with a larger disk than requested. At present, the maximum disk size is 1000GB; builds that request more than the maximum are rejected with an error."', args=[d.arg(name='diskSizeGb', type=d.T.integer)]),
          withDiskSizeGb(diskSizeGb): { diskSizeGb: diskSizeGb },
          '#withDynamicSubstitutions':: d.fn(help='"Option to specify whether or not to apply bash style string operations to the substitutions. \\n NOTE this is always enabled for triggered builds and cannot be overridden in the build configuration file."', args=[d.arg(name='dynamicSubstitutions', type=d.T.boolean)]),
          withDynamicSubstitutions(dynamicSubstitutions): { dynamicSubstitutions: dynamicSubstitutions },
          '#withEnv':: d.fn(help='"A list of global environment variable definitions that will exist for all build steps in this build. If a variable is defined in both globally and in a build step, the variable will use the build step value. \\n The elements are of the form \\"KEY=VALUE\\" for the environment variable \\"KEY\\" being given the value \\"VALUE\\"."', args=[d.arg(name='env', type=d.T.array)]),
          withEnv(env): { env: if std.isArray(v=env) then env else [env] },
          '#withEnvMixin':: d.fn(help='"A list of global environment variable definitions that will exist for all build steps in this build. If a variable is defined in both globally and in a build step, the variable will use the build step value. \\n The elements are of the form \\"KEY=VALUE\\" for the environment variable \\"KEY\\" being given the value \\"VALUE\\"."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
          withEnvMixin(env): { env+: if std.isArray(v=env) then env else [env] },
          '#withLogStreamingOption':: d.fn(help='"Option to define build log streaming behavior to Google Cloud Storage. Possible values: [\\"STREAM_DEFAULT\\", \\"STREAM_ON\\", \\"STREAM_OFF\\"]"', args=[d.arg(name='logStreamingOption', type=d.T.string)]),
          withLogStreamingOption(logStreamingOption): { logStreamingOption: logStreamingOption },
          '#withLogging':: d.fn(help='"Option to specify the logging mode, which determines if and where build logs are stored. Possible values: [\\"LOGGING_UNSPECIFIED\\", \\"LEGACY\\", \\"GCS_ONLY\\", \\"STACKDRIVER_ONLY\\", \\"NONE\\"]"', args=[d.arg(name='logging', type=d.T.string)]),
          withLogging(logging): { logging: logging },
          '#withMachineType':: d.fn(help='"Compute Engine machine type on which to run the build. Possible values: [\\"UNSPECIFIED\\", \\"N1_HIGHCPU_8\\", \\"N1_HIGHCPU_32\\", \\"E2_HIGHCPU_8\\", \\"E2_HIGHCPU_32\\"]"', args=[d.arg(name='machineType', type=d.T.string)]),
          withMachineType(machineType): { machineType: machineType },
          '#withRequestedVerifyOption':: d.fn(help='"Requested verifiability options. Possible values: [\\"NOT_VERIFIED\\", \\"VERIFIED\\"]"', args=[d.arg(name='requestedVerifyOption', type=d.T.string)]),
          withRequestedVerifyOption(requestedVerifyOption): { requestedVerifyOption: requestedVerifyOption },
          '#withSecretEnv':: d.fn(help="\"A list of global environment variables, which are encrypted using a Cloud Key Management Service crypto key. These values must be specified in the build's Secret. These variables will be available to all build steps in this build.\"", args=[d.arg(name='secretEnv', type=d.T.array)]),
          withSecretEnv(secretEnv): { secretEnv: if std.isArray(v=secretEnv) then secretEnv else [secretEnv] },
          '#withSecretEnvMixin':: d.fn(help="\"A list of global environment variables, which are encrypted using a Cloud Key Management Service crypto key. These values must be specified in the build's Secret. These variables will be available to all build steps in this build.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='secretEnv', type=d.T.array)]),
          withSecretEnvMixin(secretEnv): { secretEnv+: if std.isArray(v=secretEnv) then secretEnv else [secretEnv] },
          '#withSourceProvenanceHash':: d.fn(help='"Requested hash for SourceProvenance. Possible values: [\\"NONE\\", \\"SHA256\\", \\"MD5\\"]"', args=[d.arg(name='sourceProvenanceHash', type=d.T.array)]),
          withSourceProvenanceHash(sourceProvenanceHash): { sourceProvenanceHash: if std.isArray(v=sourceProvenanceHash) then sourceProvenanceHash else [sourceProvenanceHash] },
          '#withSourceProvenanceHashMixin':: d.fn(help='"Requested hash for SourceProvenance. Possible values: [\\"NONE\\", \\"SHA256\\", \\"MD5\\"]"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sourceProvenanceHash', type=d.T.array)]),
          withSourceProvenanceHashMixin(sourceProvenanceHash): { sourceProvenanceHash+: if std.isArray(v=sourceProvenanceHash) then sourceProvenanceHash else [sourceProvenanceHash] },
          '#withSubstitutionOption':: d.fn(help='"Option to specify behavior when there is an error in the substitution checks. \\n NOTE this is always set to ALLOW_LOOSE for triggered builds and cannot be overridden in the build configuration file. Possible values: [\\"MUST_MATCH\\", \\"ALLOW_LOOSE\\"]"', args=[d.arg(name='substitutionOption', type=d.T.string)]),
          withSubstitutionOption(substitutionOption): { substitutionOption: substitutionOption },
          '#withVolumes':: d.fn(help='"Global list of volumes to mount for ALL build steps \\n Each volume is created as an empty volume prior to starting the build process. Upon completion of the build, volumes and their contents are discarded. Global volume names and paths cannot conflict with the volumes defined a build step. \\n Using a global volume in a build with only one step is not valid as it is indicative of a build request with an incorrect configuration."', args=[d.arg(name='volumes', type=d.T.array)]),
          withVolumes(volumes): { volumes: if std.isArray(v=volumes) then volumes else [volumes] },
          '#withVolumesMixin':: d.fn(help='"Global list of volumes to mount for ALL build steps \\n Each volume is created as an empty volume prior to starting the build process. Upon completion of the build, volumes and their contents are discarded. Global volume names and paths cannot conflict with the volumes defined a build step. \\n Using a global volume in a build with only one step is not valid as it is indicative of a build request with an incorrect configuration."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumes', type=d.T.array)]),
          withVolumesMixin(volumes): { volumes+: if std.isArray(v=volumes) then volumes else [volumes] },
          '#withWorkerPool':: d.fn(help='"Option to specify a WorkerPool for the build. Format projects/{project}/workerPools/{workerPool} \\n This field is experimental."', args=[d.arg(name='workerPool', type=d.T.string)]),
          withWorkerPool(workerPool): { workerPool: workerPool },
        },
        '#secret':: d.obj(help='"Secrets to decrypt using Cloud Key Management Service."'),
        secret: {
          '#withKmsKeyName':: d.fn(help='"Cloud KMS key name to use to decrypt these envs."', args=[d.arg(name='kmsKeyName', type=d.T.string)]),
          withKmsKeyName(kmsKeyName): { kmsKeyName: kmsKeyName },
          '#withSecretEnv':: d.fn(help="\"Map of environment variable name to its encrypted value. Secret environment variables must be unique across all of a build's secrets, and must be used by at least one build step. Values can be at most 64 KB in size. There can be at most 100 secret values across all of a build's secrets.\"", args=[d.arg(name='secretEnv', type=d.T.object)]),
          withSecretEnv(secretEnv): { secretEnv: secretEnv },
          '#withSecretEnvMixin':: d.fn(help="\"Map of environment variable name to its encrypted value. Secret environment variables must be unique across all of a build's secrets, and must be used by at least one build step. Values can be at most 64 KB in size. There can be at most 100 secret values across all of a build's secrets.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='secretEnv', type=d.T.object)]),
          withSecretEnvMixin(secretEnv): { secretEnv+: secretEnv },
        },
        '#source':: d.obj(help="\"The location of the source files to build. \\n One of 'storageSource' or 'repoSource' must be provided.\""),
        source: {
          '#repoSource':: d.obj(help='"Location of the source in a Google Cloud Source Repository."'),
          repoSource: {
            '#withBranchName':: d.fn(help='"Regex matching branches to build. Exactly one a of branch name, tag, or commit SHA must be provided. The syntax of the regular expressions accepted is the syntax accepted by RE2 and described at https://github.com/google/re2/wiki/Syntax"', args=[d.arg(name='branchName', type=d.T.string)]),
            withBranchName(branchName): { branchName: branchName },
            '#withCommitSha':: d.fn(help='"Explicit commit SHA to build. Exactly one a of branch name, tag, or commit SHA must be provided."', args=[d.arg(name='commitSha', type=d.T.string)]),
            withCommitSha(commitSha): { commitSha: commitSha },
            '#withDir':: d.fn(help="\"Directory, relative to the source root, in which to run the build. This must be a relative path. If a step's dir is specified and is an absolute path, this value is ignored for that step's execution.\"", args=[d.arg(name='dir', type=d.T.string)]),
            withDir(dir): { dir: dir },
            '#withInvertRegex':: d.fn(help='"Only trigger a build if the revision regex does NOT match the revision regex."', args=[d.arg(name='invertRegex', type=d.T.boolean)]),
            withInvertRegex(invertRegex): { invertRegex: invertRegex },
            '#withProjectId':: d.fn(help='"ID of the project that owns the Cloud Source Repository. If omitted, the project ID requesting the build is assumed."', args=[d.arg(name='projectId', type=d.T.string)]),
            withProjectId(projectId): { projectId: projectId },
            '#withRepoName':: d.fn(help='"Name of the Cloud Source Repository."', args=[d.arg(name='repoName', type=d.T.string)]),
            withRepoName(repoName): { repoName: repoName },
            '#withSubstitutions':: d.fn(help='"Substitutions to use in a triggered build. Should only be used with triggers.run"', args=[d.arg(name='substitutions', type=d.T.object)]),
            withSubstitutions(substitutions): { substitutions: substitutions },
            '#withSubstitutionsMixin':: d.fn(help='"Substitutions to use in a triggered build. Should only be used with triggers.run"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='substitutions', type=d.T.object)]),
            withSubstitutionsMixin(substitutions): { substitutions+: substitutions },
            '#withTagName':: d.fn(help='"Regex matching tags to build. Exactly one a of branch name, tag, or commit SHA must be provided. The syntax of the regular expressions accepted is the syntax accepted by RE2 and described at https://github.com/google/re2/wiki/Syntax"', args=[d.arg(name='tagName', type=d.T.string)]),
            withTagName(tagName): { tagName: tagName },
          },
          '#storageSource':: d.obj(help='"Location of the source in an archive file in Google Cloud Storage."'),
          storageSource: {
            '#withBucket':: d.fn(help='"Google Cloud Storage bucket containing the source."', args=[d.arg(name='bucket', type=d.T.string)]),
            withBucket(bucket): { bucket: bucket },
            '#withGeneration':: d.fn(help='"Google Cloud Storage generation for the object. If the generation is omitted, the latest generation will be used"', args=[d.arg(name='generation', type=d.T.string)]),
            withGeneration(generation): { generation: generation },
            '#withObject':: d.fn(help='"Google Cloud Storage object containing the source. This object must be a gzipped archive file (.tar.gz) containing source to build."', args=[d.arg(name='object', type=d.T.string)]),
            withObject(object): { object: object },
          },
          '#withRepoSource':: d.fn(help='"Location of the source in a Google Cloud Source Repository."', args=[d.arg(name='repoSource', type=d.T.array)]),
          withRepoSource(repoSource): { repoSource: if std.isArray(v=repoSource) then repoSource else [repoSource] },
          '#withRepoSourceMixin':: d.fn(help='"Location of the source in a Google Cloud Source Repository."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='repoSource', type=d.T.array)]),
          withRepoSourceMixin(repoSource): { repoSource+: if std.isArray(v=repoSource) then repoSource else [repoSource] },
          '#withStorageSource':: d.fn(help='"Location of the source in an archive file in Google Cloud Storage."', args=[d.arg(name='storageSource', type=d.T.array)]),
          withStorageSource(storageSource): { storageSource: if std.isArray(v=storageSource) then storageSource else [storageSource] },
          '#withStorageSourceMixin':: d.fn(help='"Location of the source in an archive file in Google Cloud Storage."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='storageSource', type=d.T.array)]),
          withStorageSourceMixin(storageSource): { storageSource+: if std.isArray(v=storageSource) then storageSource else [storageSource] },
        },
        '#step':: d.obj(help='"The operations to be performed on the workspace."'),
        step: {
          '#volumes':: d.obj(help='"List of volumes to mount into the build step. \\n Each volume is created as an empty volume prior to execution of the build step. Upon completion of the build, volumes and their contents are discarded. \\n Using a named volume in only one step is not valid as it is indicative of a build request with an incorrect configuration."'),
          volumes: {
            '#withName':: d.fn(help='"Name of the volume to mount. \\n Volume names must be unique per build step and must be valid names for Docker volumes. Each named volume must be used by at least two build steps."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withPath':: d.fn(help='"Path at which to mount the volume. \\n Paths must be absolute and cannot conflict with other volume paths on the same build step or with certain reserved volume paths."', args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { path: path },
          },
          '#withArgs':: d.fn(help="\"A list of arguments that will be presented to the step when it is started. \\n If the image used to run the step's container has an entrypoint, the args are used as arguments to that entrypoint. If the image does not define an entrypoint, the first element in args is used as the entrypoint, and the remainder will be used as arguments.\"", args=[d.arg(name='args', type=d.T.array)]),
          withArgs(args): { args: if std.isArray(v=args) then args else [args] },
          '#withArgsMixin':: d.fn(help="\"A list of arguments that will be presented to the step when it is started. \\n If the image used to run the step's container has an entrypoint, the args are used as arguments to that entrypoint. If the image does not define an entrypoint, the first element in args is used as the entrypoint, and the remainder will be used as arguments.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='args', type=d.T.array)]),
          withArgsMixin(args): { args+: if std.isArray(v=args) then args else [args] },
          '#withDir':: d.fn(help="\"Working directory to use when running this step's container. \\n If this value is a relative path, it is relative to the build's working directory. If this value is absolute, it may be outside the build's working directory, in which case the contents of the path may not be persisted across build step executions, unless a 'volume' for that path is specified. \\n If the build specifies a 'RepoSource' with 'dir' and a step with a 'dir', which specifies an absolute path, the 'RepoSource' 'dir' is ignored for the step's execution.\"", args=[d.arg(name='dir', type=d.T.string)]),
          withDir(dir): { dir: dir },
          '#withEntrypoint':: d.fn(help="\"Entrypoint to be used instead of the build step image's default entrypoint. If unset, the image's default entrypoint is used\"", args=[d.arg(name='entrypoint', type=d.T.string)]),
          withEntrypoint(entrypoint): { entrypoint: entrypoint },
          '#withEnv':: d.fn(help='"A list of environment variable definitions to be used when running a step. \\n The elements are of the form \\"KEY=VALUE\\" for the environment variable \\"KEY\\" being given the value \\"VALUE\\"."', args=[d.arg(name='env', type=d.T.array)]),
          withEnv(env): { env: if std.isArray(v=env) then env else [env] },
          '#withEnvMixin':: d.fn(help='"A list of environment variable definitions to be used when running a step. \\n The elements are of the form \\"KEY=VALUE\\" for the environment variable \\"KEY\\" being given the value \\"VALUE\\"."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
          withEnvMixin(env): { env+: if std.isArray(v=env) then env else [env] },
          '#withId':: d.fn(help="\"Unique identifier for this build step, used in 'wait_for' to reference this build step as a dependency.\"", args=[d.arg(name='id', type=d.T.string)]),
          withId(id): { id: id },
          '#withName':: d.fn(help="\"The name of the container image that will run this particular build step. \\n If the image is available in the host's Docker daemon's cache, it will be run directly. If not, the host will attempt to pull the image first, using the builder service account's credentials if necessary. \\n The Docker daemon's cache will already have the latest versions of all of the officially supported build steps (see https://github.com/GoogleCloudPlatform/cloud-builders for images and examples). The Docker daemon will also have cached many of the layers for some popular images, like \\\"ubuntu\\\", \\\"debian\\\", but they will be refreshed at the time you attempt to use them. \\n If you built an image in a previous build step, it will be stored in the host's Docker daemon's cache and is available to use as the name for a later build step.\"", args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withSecretEnv':: d.fn(help="\"A list of environment variables which are encrypted using a Cloud Key Management Service crypto key. These values must be specified in the build's 'Secret'.\"", args=[d.arg(name='secretEnv', type=d.T.array)]),
          withSecretEnv(secretEnv): { secretEnv: if std.isArray(v=secretEnv) then secretEnv else [secretEnv] },
          '#withSecretEnvMixin':: d.fn(help="\"A list of environment variables which are encrypted using a Cloud Key Management Service crypto key. These values must be specified in the build's 'Secret'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='secretEnv', type=d.T.array)]),
          withSecretEnvMixin(secretEnv): { secretEnv+: if std.isArray(v=secretEnv) then secretEnv else [secretEnv] },
          '#withTimeout':: d.fn(help='"Time limit for executing this build step. If not defined, the step has no time limit and will be allowed to continue to run until either it completes or the build itself times out."', args=[d.arg(name='timeout', type=d.T.string)]),
          withTimeout(timeout): { timeout: timeout },
          '#withTiming':: d.fn(help='"Output only. Stores timing information for executing this build step."', args=[d.arg(name='timing', type=d.T.string)]),
          withTiming(timing): { timing: timing },
          '#withVolumes':: d.fn(help='"List of volumes to mount into the build step. \\n Each volume is created as an empty volume prior to execution of the build step. Upon completion of the build, volumes and their contents are discarded. \\n Using a named volume in only one step is not valid as it is indicative of a build request with an incorrect configuration."', args=[d.arg(name='volumes', type=d.T.array)]),
          withVolumes(volumes): { volumes: if std.isArray(v=volumes) then volumes else [volumes] },
          '#withVolumesMixin':: d.fn(help='"List of volumes to mount into the build step. \\n Each volume is created as an empty volume prior to execution of the build step. Upon completion of the build, volumes and their contents are discarded. \\n Using a named volume in only one step is not valid as it is indicative of a build request with an incorrect configuration."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumes', type=d.T.array)]),
          withVolumesMixin(volumes): { volumes+: if std.isArray(v=volumes) then volumes else [volumes] },
          '#withWaitFor':: d.fn(help="\"The ID(s) of the step(s) that this build step depends on. \\n This build step will not start until all the build steps in 'wait_for' have completed successfully. If 'wait_for' is empty, this build step will start when all previous build steps in the 'Build.Steps' list have completed successfully.\"", args=[d.arg(name='waitFor', type=d.T.array)]),
          withWaitFor(waitFor): { waitFor: if std.isArray(v=waitFor) then waitFor else [waitFor] },
          '#withWaitForMixin':: d.fn(help="\"The ID(s) of the step(s) that this build step depends on. \\n This build step will not start until all the build steps in 'wait_for' have completed successfully. If 'wait_for' is empty, this build step will start when all previous build steps in the 'Build.Steps' list have completed successfully.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='waitFor', type=d.T.array)]),
          withWaitForMixin(waitFor): { waitFor+: if std.isArray(v=waitFor) then waitFor else [waitFor] },
        },
        '#withArtifacts':: d.fn(help='"Artifacts produced by the build that should be uploaded upon successful completion of all build steps."', args=[d.arg(name='artifacts', type=d.T.array)]),
        withArtifacts(artifacts): { artifacts: if std.isArray(v=artifacts) then artifacts else [artifacts] },
        '#withArtifactsMixin':: d.fn(help='"Artifacts produced by the build that should be uploaded upon successful completion of all build steps."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='artifacts', type=d.T.array)]),
        withArtifactsMixin(artifacts): { artifacts+: if std.isArray(v=artifacts) then artifacts else [artifacts] },
        '#withImages':: d.fn(help="\"A list of images to be pushed upon the successful completion of all build steps. The images are pushed using the builder service account's credentials. The digests of the pushed images will be stored in the Build resource's results field. If any of the images fail to be pushed, the build status is marked FAILURE.\"", args=[d.arg(name='images', type=d.T.array)]),
        withImages(images): { images: if std.isArray(v=images) then images else [images] },
        '#withImagesMixin':: d.fn(help="\"A list of images to be pushed upon the successful completion of all build steps. The images are pushed using the builder service account's credentials. The digests of the pushed images will be stored in the Build resource's results field. If any of the images fail to be pushed, the build status is marked FAILURE.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='images', type=d.T.array)]),
        withImagesMixin(images): { images+: if std.isArray(v=images) then images else [images] },
        '#withLogsBucket':: d.fn(help='"Google Cloud Storage bucket where logs should be written. Logs file names will be of the format ${logsBucket}/log-${build_id}.txt."', args=[d.arg(name='logsBucket', type=d.T.string)]),
        withLogsBucket(logsBucket): { logsBucket: logsBucket },
        '#withOptions':: d.fn(help='"Special options for this build."', args=[d.arg(name='options', type=d.T.array)]),
        withOptions(options): { options: if std.isArray(v=options) then options else [options] },
        '#withOptionsMixin':: d.fn(help='"Special options for this build."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='options', type=d.T.array)]),
        withOptionsMixin(options): { options+: if std.isArray(v=options) then options else [options] },
        '#withQueueTtl':: d.fn(help="\"TTL in queue for this build. If provided and the build is enqueued longer than this value, the build will expire and the build status will be EXPIRED. The TTL starts ticking from createTime. A duration in seconds with up to nine fractional digits, terminated by 's'. Example: \\\"3.5s\\\".\"", args=[d.arg(name='queueTtl', type=d.T.string)]),
        withQueueTtl(queueTtl): { queueTtl: queueTtl },
        '#withSecret':: d.fn(help='"Secrets to decrypt using Cloud Key Management Service."', args=[d.arg(name='secret', type=d.T.array)]),
        withSecret(secret): { secret: if std.isArray(v=secret) then secret else [secret] },
        '#withSecretMixin':: d.fn(help='"Secrets to decrypt using Cloud Key Management Service."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='secret', type=d.T.array)]),
        withSecretMixin(secret): { secret+: if std.isArray(v=secret) then secret else [secret] },
        '#withSource':: d.fn(help="\"The location of the source files to build. \\n One of 'storageSource' or 'repoSource' must be provided.\"", args=[d.arg(name='source', type=d.T.array)]),
        withSource(source): { source: if std.isArray(v=source) then source else [source] },
        '#withSourceMixin':: d.fn(help="\"The location of the source files to build. \\n One of 'storageSource' or 'repoSource' must be provided.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='source', type=d.T.array)]),
        withSourceMixin(source): { source+: if std.isArray(v=source) then source else [source] },
        '#withStep':: d.fn(help='"The operations to be performed on the workspace."', args=[d.arg(name='step', type=d.T.array)]),
        withStep(step): { step: if std.isArray(v=step) then step else [step] },
        '#withStepMixin':: d.fn(help='"The operations to be performed on the workspace."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='step', type=d.T.array)]),
        withStepMixin(step): { step+: if std.isArray(v=step) then step else [step] },
        '#withSubstitutions':: d.fn(help='"Substitutions data for Build resource."', args=[d.arg(name='substitutions', type=d.T.object)]),
        withSubstitutions(substitutions): { substitutions: substitutions },
        '#withSubstitutionsMixin':: d.fn(help='"Substitutions data for Build resource."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='substitutions', type=d.T.object)]),
        withSubstitutionsMixin(substitutions): { substitutions+: substitutions },
        '#withTags':: d.fn(help='"Tags for annotation of a Build. These are not docker tags."', args=[d.arg(name='tags', type=d.T.array)]),
        withTags(tags): { tags: if std.isArray(v=tags) then tags else [tags] },
        '#withTagsMixin':: d.fn(help='"Tags for annotation of a Build. These are not docker tags."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tags', type=d.T.array)]),
        withTagsMixin(tags): { tags+: if std.isArray(v=tags) then tags else [tags] },
        '#withTimeout':: d.fn(help='"Amount of time that this build should be allowed to run, to second granularity. If this amount of time elapses, work on the build will cease and the build status will be TIMEOUT. This timeout must be equal to or greater than the sum of the timeouts for build steps within the build. The expected format is the number of seconds followed by s. Default time is ten minutes (600s)."', args=[d.arg(name='timeout', type=d.T.string)]),
        withTimeout(timeout): { timeout: timeout },
      },
      '#github':: d.obj(help="\"Describes the configuration of a trigger that creates a build whenever a GitHub event is received. \\n One of 'trigger_template', 'github', 'pubsub_config' or 'webhook_config' must be provided.\""),
      github: {
        '#pullRequest':: d.obj(help='"filter to match changes in pull requests.  Specify only one of pullRequest or push."'),
        pullRequest: {
          '#withBranch':: d.fn(help='"Regex of branches to match."', args=[d.arg(name='branch', type=d.T.string)]),
          withBranch(branch): { branch: branch },
          '#withCommentControl':: d.fn(help='"Whether to block builds on a \\"/gcbrun\\" comment from a repository owner or collaborator. Possible values: [\\"COMMENTS_DISABLED\\", \\"COMMENTS_ENABLED\\", \\"COMMENTS_ENABLED_FOR_EXTERNAL_CONTRIBUTORS_ONLY\\"]"', args=[d.arg(name='commentControl', type=d.T.string)]),
          withCommentControl(commentControl): { commentControl: commentControl },
          '#withInvertRegex':: d.fn(help='"If true, branches that do NOT match the git_ref will trigger a build."', args=[d.arg(name='invertRegex', type=d.T.boolean)]),
          withInvertRegex(invertRegex): { invertRegex: invertRegex },
        },
        '#push':: d.obj(help='"filter to match changes in refs, like branches or tags.  Specify only one of pullRequest or push."'),
        push: {
          '#withBranch':: d.fn(help='"Regex of branches to match.  Specify only one of branch or tag."', args=[d.arg(name='branch', type=d.T.string)]),
          withBranch(branch): { branch: branch },
          '#withInvertRegex':: d.fn(help='"When true, only trigger a build if the revision regex does NOT match the git_ref regex."', args=[d.arg(name='invertRegex', type=d.T.boolean)]),
          withInvertRegex(invertRegex): { invertRegex: invertRegex },
          '#withTag':: d.fn(help='"Regex of tags to match.  Specify only one of branch or tag."', args=[d.arg(name='tag', type=d.T.string)]),
          withTag(tag): { tag: tag },
        },
        '#withName':: d.fn(help='"Name of the repository. For example: The name for https://github.com/googlecloudplatform/cloud-builders is \\"cloud-builders\\"."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withOwner':: d.fn(help='"Owner of the repository. For example: The owner for https://github.com/googlecloudplatform/cloud-builders is \\"googlecloudplatform\\"."', args=[d.arg(name='owner', type=d.T.string)]),
        withOwner(owner): { owner: owner },
        '#withPullRequest':: d.fn(help='"filter to match changes in pull requests.  Specify only one of pullRequest or push."', args=[d.arg(name='pullRequest', type=d.T.array)]),
        withPullRequest(pullRequest): { pullRequest: if std.isArray(v=pullRequest) then pullRequest else [pullRequest] },
        '#withPullRequestMixin':: d.fn(help='"filter to match changes in pull requests.  Specify only one of pullRequest or push."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='pullRequest', type=d.T.array)]),
        withPullRequestMixin(pullRequest): { pullRequest+: if std.isArray(v=pullRequest) then pullRequest else [pullRequest] },
        '#withPush':: d.fn(help='"filter to match changes in refs, like branches or tags.  Specify only one of pullRequest or push."', args=[d.arg(name='push', type=d.T.array)]),
        withPush(push): { push: if std.isArray(v=push) then push else [push] },
        '#withPushMixin':: d.fn(help='"filter to match changes in refs, like branches or tags.  Specify only one of pullRequest or push."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='push', type=d.T.array)]),
        withPushMixin(push): { push+: if std.isArray(v=push) then push else [push] },
      },
      '#pubsubConfig':: d.obj(help="\"PubsubConfig describes the configuration of a trigger that creates a build whenever a Pub/Sub message is published. \\n One of 'trigger_template', 'github', 'pubsub_config' or 'webhook_config' must be provided.\""),
      pubsubConfig: {
        '#withServiceAccountEmail':: d.fn(help='"Service account that will make the push request."', args=[d.arg(name='serviceAccountEmail', type=d.T.string)]),
        withServiceAccountEmail(serviceAccountEmail): { serviceAccountEmail: serviceAccountEmail },
        '#withTopic':: d.fn(help='"The name of the topic from which this subscription is receiving messages."', args=[d.arg(name='topic', type=d.T.string)]),
        withTopic(topic): { topic: topic },
      },
      '#triggerTemplate':: d.obj(help="\"Template describing the types of source changes to trigger a build. \\n Branch and tag names in trigger templates are interpreted as regular expressions. Any branch or tag change that matches that regular expression will trigger a build. \\n One of 'trigger_template', 'github', 'pubsub_config' or 'webhook_config' must be provided.\""),
      triggerTemplate: {
        '#withBranchName':: d.fn(help='"Name of the branch to build. Exactly one a of branch name, tag, or commit SHA must be provided. This field is a regular expression."', args=[d.arg(name='branchName', type=d.T.string)]),
        withBranchName(branchName): { branchName: branchName },
        '#withCommitSha':: d.fn(help='"Explicit commit SHA to build. Exactly one of a branch name, tag, or commit SHA must be provided."', args=[d.arg(name='commitSha', type=d.T.string)]),
        withCommitSha(commitSha): { commitSha: commitSha },
        '#withDir':: d.fn(help="\"Directory, relative to the source root, in which to run the build. \\n This must be a relative path. If a step's dir is specified and is an absolute path, this value is ignored for that step's execution.\"", args=[d.arg(name='dir', type=d.T.string)]),
        withDir(dir): { dir: dir },
        '#withInvertRegex':: d.fn(help='"Only trigger a build if the revision regex does NOT match the revision regex."', args=[d.arg(name='invertRegex', type=d.T.boolean)]),
        withInvertRegex(invertRegex): { invertRegex: invertRegex },
        '#withProjectId':: d.fn(help='"ID of the project that owns the Cloud Source Repository. If omitted, the project ID requesting the build is assumed."', args=[d.arg(name='projectId', type=d.T.string)]),
        withProjectId(projectId): { projectId: projectId },
        '#withRepoName':: d.fn(help='"Name of the Cloud Source Repository. If omitted, the name \\"default\\" is assumed."', args=[d.arg(name='repoName', type=d.T.string)]),
        withRepoName(repoName): { repoName: repoName },
        '#withTagName':: d.fn(help='"Name of the tag to build. Exactly one of a branch name, tag, or commit SHA must be provided. This field is a regular expression."', args=[d.arg(name='tagName', type=d.T.string)]),
        withTagName(tagName): { tagName: tagName },
      },
      '#webhookConfig':: d.obj(help="\"WebhookConfig describes the configuration of a trigger that creates a build whenever a webhook is sent to a trigger's webhook URL. \\n One of 'trigger_template', 'github', 'pubsub_config' or 'webhook_config' must be provided.\""),
      webhookConfig: {
        '#withSecret':: d.fn(help='"Resource name for the secret required as a URL parameter."', args=[d.arg(name='secret', type=d.T.string)]),
        withSecret(secret): { secret: secret },
      },
      '#withBuild':: d.fn(help='"Contents of the build template. Either a filename or build template must be provided."', args=[d.arg(name='build', type=d.T.array)]),
      withBuild(build): { spec+: { forProvider+: { build: if std.isArray(v=build) then build else [build] } } },
      '#withBuildMixin':: d.fn(help='"Contents of the build template. Either a filename or build template must be provided."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='build', type=d.T.array)]),
      withBuildMixin(build): { spec+: { forProvider+: { build+: if std.isArray(v=build) then build else [build] } } },
      '#withDescription':: d.fn(help='"Human-readable description of the trigger."', args=[d.arg(name='description', type=d.T.string)]),
      withDescription(description): { spec+: { forProvider+: { description: description } } },
      '#withDisabled':: d.fn(help='"Whether the trigger is disabled or not. If true, the trigger will never result in a build."', args=[d.arg(name='disabled', type=d.T.boolean)]),
      withDisabled(disabled): { spec+: { forProvider+: { disabled: disabled } } },
      '#withFilename':: d.fn(help='"Path, from the source root, to a file whose contents is used for the template. Either a filename or build template must be provided."', args=[d.arg(name='filename', type=d.T.string)]),
      withFilename(filename): { spec+: { forProvider+: { filename: filename } } },
      '#withGithub':: d.fn(help="\"Describes the configuration of a trigger that creates a build whenever a GitHub event is received. \\n One of 'trigger_template', 'github', 'pubsub_config' or 'webhook_config' must be provided.\"", args=[d.arg(name='github', type=d.T.array)]),
      withGithub(github): { spec+: { forProvider+: { github: if std.isArray(v=github) then github else [github] } } },
      '#withGithubMixin':: d.fn(help="\"Describes the configuration of a trigger that creates a build whenever a GitHub event is received. \\n One of 'trigger_template', 'github', 'pubsub_config' or 'webhook_config' must be provided.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='github', type=d.T.array)]),
      withGithubMixin(github): { spec+: { forProvider+: { github+: if std.isArray(v=github) then github else [github] } } },
      '#withIgnoredFiles':: d.fn(help="\"ignoredFiles and includedFiles are file glob matches using https://golang.org/pkg/path/filepath/#Match extended with support for '**'. \\n If ignoredFiles and changed files are both empty, then they are not used to determine whether or not to trigger a build. \\n If ignoredFiles is not empty, then we ignore any files that match any of the ignored_file globs. If the change has no files that are outside of the ignoredFiles globs, then we do not trigger a build.\"", args=[d.arg(name='ignoredFiles', type=d.T.array)]),
      withIgnoredFiles(ignoredFiles): { spec+: { forProvider+: { ignoredFiles: if std.isArray(v=ignoredFiles) then ignoredFiles else [ignoredFiles] } } },
      '#withIgnoredFilesMixin':: d.fn(help="\"ignoredFiles and includedFiles are file glob matches using https://golang.org/pkg/path/filepath/#Match extended with support for '**'. \\n If ignoredFiles and changed files are both empty, then they are not used to determine whether or not to trigger a build. \\n If ignoredFiles is not empty, then we ignore any files that match any of the ignored_file globs. If the change has no files that are outside of the ignoredFiles globs, then we do not trigger a build.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='ignoredFiles', type=d.T.array)]),
      withIgnoredFilesMixin(ignoredFiles): { spec+: { forProvider+: { ignoredFiles+: if std.isArray(v=ignoredFiles) then ignoredFiles else [ignoredFiles] } } },
      '#withIncludedFiles':: d.fn(help="\"ignoredFiles and includedFiles are file glob matches using https://golang.org/pkg/path/filepath/#Match extended with support for '**'. \\n If any of the files altered in the commit pass the ignoredFiles filter and includedFiles is empty, then as far as this filter is concerned, we should trigger the build. \\n If any of the files altered in the commit pass the ignoredFiles filter and includedFiles is not empty, then we make sure that at least one of those files matches a includedFiles glob. If not, then we do not trigger a build.\"", args=[d.arg(name='includedFiles', type=d.T.array)]),
      withIncludedFiles(includedFiles): { spec+: { forProvider+: { includedFiles: if std.isArray(v=includedFiles) then includedFiles else [includedFiles] } } },
      '#withIncludedFilesMixin':: d.fn(help="\"ignoredFiles and includedFiles are file glob matches using https://golang.org/pkg/path/filepath/#Match extended with support for '**'. \\n If any of the files altered in the commit pass the ignoredFiles filter and includedFiles is empty, then as far as this filter is concerned, we should trigger the build. \\n If any of the files altered in the commit pass the ignoredFiles filter and includedFiles is not empty, then we make sure that at least one of those files matches a includedFiles glob. If not, then we do not trigger a build.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='includedFiles', type=d.T.array)]),
      withIncludedFilesMixin(includedFiles): { spec+: { forProvider+: { includedFiles+: if std.isArray(v=includedFiles) then includedFiles else [includedFiles] } } },
      '#withName':: d.fn(help='"Name of the trigger. Must be unique within the project."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { forProvider+: { name: name } } },
      '#withProject':: d.fn(help='', args=[d.arg(name='project', type=d.T.string)]),
      withProject(project): { spec+: { forProvider+: { project: project } } },
      '#withPubsubConfig':: d.fn(help="\"PubsubConfig describes the configuration of a trigger that creates a build whenever a Pub/Sub message is published. \\n One of 'trigger_template', 'github', 'pubsub_config' or 'webhook_config' must be provided.\"", args=[d.arg(name='pubsubConfig', type=d.T.array)]),
      withPubsubConfig(pubsubConfig): { spec+: { forProvider+: { pubsubConfig: if std.isArray(v=pubsubConfig) then pubsubConfig else [pubsubConfig] } } },
      '#withPubsubConfigMixin':: d.fn(help="\"PubsubConfig describes the configuration of a trigger that creates a build whenever a Pub/Sub message is published. \\n One of 'trigger_template', 'github', 'pubsub_config' or 'webhook_config' must be provided.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='pubsubConfig', type=d.T.array)]),
      withPubsubConfigMixin(pubsubConfig): { spec+: { forProvider+: { pubsubConfig+: if std.isArray(v=pubsubConfig) then pubsubConfig else [pubsubConfig] } } },
      '#withServiceAccount':: d.fn(help='"The service account used for all user-controlled operations including triggers.patch, triggers.run, builds.create, and builds.cancel. \\n If no service account is set, then the standard Cloud Build service account ([PROJECT_NUM]@system.gserviceaccount.com) will be used instead. \\n Format: projects/{PROJECT_ID}/serviceAccounts/{ACCOUNT_ID_OR_EMAIL}"', args=[d.arg(name='serviceAccount', type=d.T.string)]),
      withServiceAccount(serviceAccount): { spec+: { forProvider+: { serviceAccount: serviceAccount } } },
      '#withSubstitutions':: d.fn(help='"Substitutions data for Build resource."', args=[d.arg(name='substitutions', type=d.T.object)]),
      withSubstitutions(substitutions): { spec+: { forProvider+: { substitutions: substitutions } } },
      '#withSubstitutionsMixin':: d.fn(help='"Substitutions data for Build resource."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='substitutions', type=d.T.object)]),
      withSubstitutionsMixin(substitutions): { spec+: { forProvider+: { substitutions+: substitutions } } },
      '#withTags':: d.fn(help='"Tags for annotation of a BuildTrigger"', args=[d.arg(name='tags', type=d.T.array)]),
      withTags(tags): { spec+: { forProvider+: { tags: if std.isArray(v=tags) then tags else [tags] } } },
      '#withTagsMixin':: d.fn(help='"Tags for annotation of a BuildTrigger"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tags', type=d.T.array)]),
      withTagsMixin(tags): { spec+: { forProvider+: { tags+: if std.isArray(v=tags) then tags else [tags] } } },
      '#withTriggerTemplate':: d.fn(help="\"Template describing the types of source changes to trigger a build. \\n Branch and tag names in trigger templates are interpreted as regular expressions. Any branch or tag change that matches that regular expression will trigger a build. \\n One of 'trigger_template', 'github', 'pubsub_config' or 'webhook_config' must be provided.\"", args=[d.arg(name='triggerTemplate', type=d.T.array)]),
      withTriggerTemplate(triggerTemplate): { spec+: { forProvider+: { triggerTemplate: if std.isArray(v=triggerTemplate) then triggerTemplate else [triggerTemplate] } } },
      '#withTriggerTemplateMixin':: d.fn(help="\"Template describing the types of source changes to trigger a build. \\n Branch and tag names in trigger templates are interpreted as regular expressions. Any branch or tag change that matches that regular expression will trigger a build. \\n One of 'trigger_template', 'github', 'pubsub_config' or 'webhook_config' must be provided.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='triggerTemplate', type=d.T.array)]),
      withTriggerTemplateMixin(triggerTemplate): { spec+: { forProvider+: { triggerTemplate+: if std.isArray(v=triggerTemplate) then triggerTemplate else [triggerTemplate] } } },
      '#withWebhookConfig':: d.fn(help="\"WebhookConfig describes the configuration of a trigger that creates a build whenever a webhook is sent to a trigger's webhook URL. \\n One of 'trigger_template', 'github', 'pubsub_config' or 'webhook_config' must be provided.\"", args=[d.arg(name='webhookConfig', type=d.T.array)]),
      withWebhookConfig(webhookConfig): { spec+: { forProvider+: { webhookConfig: if std.isArray(v=webhookConfig) then webhookConfig else [webhookConfig] } } },
      '#withWebhookConfigMixin':: d.fn(help="\"WebhookConfig describes the configuration of a trigger that creates a build whenever a webhook is sent to a trigger's webhook URL. \\n One of 'trigger_template', 'github', 'pubsub_config' or 'webhook_config' must be provided.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='webhookConfig', type=d.T.array)]),
      withWebhookConfigMixin(webhookConfig): { spec+: { forProvider+: { webhookConfig+: if std.isArray(v=webhookConfig) then webhookConfig else [webhookConfig] } } },
    },
    '#providerConfigRef':: d.obj(help='"ProviderConfigReference specifies how the provider that will be used to create, observe, update, and delete this managed resource should be configured."'),
    providerConfigRef: {
      '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { providerConfigRef+: { name: name } } },
    },
    '#providerRef':: d.obj(help='"ProviderReference specifies the provider that will be used to create, observe, update, and delete this managed resource. Deprecated: Please use ProviderConfigReference, i.e. `providerConfigRef`"'),
    providerRef: {
      '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { providerRef+: { name: name } } },
    },
    '#withDeletionPolicy':: d.fn(help='"DeletionPolicy specifies what will happen to the underlying external when this managed resource is deleted - either \\"Delete\\" or \\"Orphan\\" the external resource."', args=[d.arg(name='deletionPolicy', type=d.T.string)]),
    withDeletionPolicy(deletionPolicy): { spec+: { deletionPolicy: deletionPolicy } },
    '#writeConnectionSecretToRef':: d.obj(help='"WriteConnectionSecretToReference specifies the namespace and name of a Secret to which any connection details for this managed resource should be written. Connection details frequently include the endpoint, username, and password required to connect to the managed resource."'),
    writeConnectionSecretToRef: {
      '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { writeConnectionSecretToRef+: { name: name } } },
      '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
      withNamespace(namespace): { spec+: { writeConnectionSecretToRef+: { namespace: namespace } } },
    },
  },
  '#mixin': 'ignore',
  mixin: self,
}
