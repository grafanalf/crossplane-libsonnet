{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='kubernetesCluster', url='', help='"KubernetesCluster is the Schema for the KubernetesClusters API. Manages a managed Kubernetes Cluster (also known as AKS / Azure Kubernetes Service)"'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of KubernetesCluster', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'containerservice.azure.upbound.io/v1beta1',
    kind: 'KubernetesCluster',
  } + self.metadata.withName(name=name) + self.metadata.withAnnotations(annotations={
    'tanka.dev/namespaced': 'false',
  }),
  '#spec':: d.obj(help='"KubernetesClusterSpec defines the desired state of KubernetesCluster"'),
  spec: {
    '#forProvider':: d.obj(help=''),
    forProvider: {
      '#aciConnectorLinux':: d.obj(help='"A aci_connector_linux block as defined below. For more details, please visit Create and configure an AKS cluster to use virtual nodes."'),
      aciConnectorLinux: {
        '#subnetNameRef':: d.obj(help='"Reference to a Subnet in network to populate subnetName."'),
        subnetNameRef: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetNameRef+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetNameRef+: { policy+: { resolve: resolve } } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { subnetNameRef+: { name: name } },
        },
        '#subnetNameSelector':: d.obj(help='"Selector for a Subnet in network to populate subnetName."'),
        subnetNameSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetNameSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetNameSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference as the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { subnetNameSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { subnetNameSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { subnetNameSelector+: { matchLabels+: matchLabels } },
        },
        '#withSubnetName':: d.fn(help='"The subnet name for the virtual nodes to run."', args=[d.arg(name='subnetName', type=d.T.string)]),
        withSubnetName(subnetName): { subnetName: subnetName },
      },
      '#autoScalerProfile':: d.obj(help='"A auto_scaler_profile block as defined below."'),
      autoScalerProfile: {
        '#withBalanceSimilarNodeGroups':: d.fn(help='"Detect similar node groups and balance the number of nodes between them. Defaults to false."', args=[d.arg(name='balanceSimilarNodeGroups', type=d.T.boolean)]),
        withBalanceSimilarNodeGroups(balanceSimilarNodeGroups): { balanceSimilarNodeGroups: balanceSimilarNodeGroups },
        '#withEmptyBulkDeleteMax':: d.fn(help='"Maximum number of empty nodes that can be deleted at the same time. Defaults to 10."', args=[d.arg(name='emptyBulkDeleteMax', type=d.T.string)]),
        withEmptyBulkDeleteMax(emptyBulkDeleteMax): { emptyBulkDeleteMax: emptyBulkDeleteMax },
        '#withExpander':: d.fn(help='"Expander to use. Possible values are least-waste, priority, most-pods and random. Defaults to random."', args=[d.arg(name='expander', type=d.T.string)]),
        withExpander(expander): { expander: expander },
        '#withMaxGracefulTerminationSec':: d.fn(help='"Maximum number of seconds the cluster autoscaler waits for pod termination when trying to scale down a node. Defaults to 600."', args=[d.arg(name='maxGracefulTerminationSec', type=d.T.string)]),
        withMaxGracefulTerminationSec(maxGracefulTerminationSec): { maxGracefulTerminationSec: maxGracefulTerminationSec },
        '#withMaxNodeProvisioningTime':: d.fn(help='"Maximum time the autoscaler waits for a node to be provisioned. Defaults to 15m."', args=[d.arg(name='maxNodeProvisioningTime', type=d.T.string)]),
        withMaxNodeProvisioningTime(maxNodeProvisioningTime): { maxNodeProvisioningTime: maxNodeProvisioningTime },
        '#withMaxUnreadyNodes':: d.fn(help='"Maximum Number of allowed unready nodes. Defaults to 3."', args=[d.arg(name='maxUnreadyNodes', type=d.T.number)]),
        withMaxUnreadyNodes(maxUnreadyNodes): { maxUnreadyNodes: maxUnreadyNodes },
        '#withMaxUnreadyPercentage':: d.fn(help='"Maximum percentage of unready nodes the cluster autoscaler will stop if the percentage is exceeded. Defaults to 45."', args=[d.arg(name='maxUnreadyPercentage', type=d.T.number)]),
        withMaxUnreadyPercentage(maxUnreadyPercentage): { maxUnreadyPercentage: maxUnreadyPercentage },
        '#withNewPodScaleUpDelay':: d.fn(help="\"For scenarios like burst/batch scale where you don't want CA to act before the kubernetes scheduler could schedule all the pods, you can tell CA to ignore unscheduled pods before they're a certain age. Defaults to 10s.\"", args=[d.arg(name='newPodScaleUpDelay', type=d.T.string)]),
        withNewPodScaleUpDelay(newPodScaleUpDelay): { newPodScaleUpDelay: newPodScaleUpDelay },
        '#withScaleDownDelayAfterAdd':: d.fn(help='"How long after the scale up of AKS nodes the scale down evaluation resumes. Defaults to 10m."', args=[d.arg(name='scaleDownDelayAfterAdd', type=d.T.string)]),
        withScaleDownDelayAfterAdd(scaleDownDelayAfterAdd): { scaleDownDelayAfterAdd: scaleDownDelayAfterAdd },
        '#withScaleDownDelayAfterDelete':: d.fn(help='"How long after node deletion that scale down evaluation resumes. Defaults to the value used for scan_interval."', args=[d.arg(name='scaleDownDelayAfterDelete', type=d.T.string)]),
        withScaleDownDelayAfterDelete(scaleDownDelayAfterDelete): { scaleDownDelayAfterDelete: scaleDownDelayAfterDelete },
        '#withScaleDownDelayAfterFailure':: d.fn(help='"How long after scale down failure that scale down evaluation resumes. Defaults to 3m."', args=[d.arg(name='scaleDownDelayAfterFailure', type=d.T.string)]),
        withScaleDownDelayAfterFailure(scaleDownDelayAfterFailure): { scaleDownDelayAfterFailure: scaleDownDelayAfterFailure },
        '#withScaleDownUnneeded':: d.fn(help='"How long a node should be unneeded before it is eligible for scale down. Defaults to 10m."', args=[d.arg(name='scaleDownUnneeded', type=d.T.string)]),
        withScaleDownUnneeded(scaleDownUnneeded): { scaleDownUnneeded: scaleDownUnneeded },
        '#withScaleDownUnready':: d.fn(help='"How long an unready node should be unneeded before it is eligible for scale down. Defaults to 20m."', args=[d.arg(name='scaleDownUnready', type=d.T.string)]),
        withScaleDownUnready(scaleDownUnready): { scaleDownUnready: scaleDownUnready },
        '#withScaleDownUtilizationThreshold':: d.fn(help='"Node utilization level, defined as sum of requested resources divided by capacity, below which a node can be considered for scale down. Defaults to 0.5."', args=[d.arg(name='scaleDownUtilizationThreshold', type=d.T.string)]),
        withScaleDownUtilizationThreshold(scaleDownUtilizationThreshold): { scaleDownUtilizationThreshold: scaleDownUtilizationThreshold },
        '#withScanInterval':: d.fn(help='"How often the AKS Cluster should be re-evaluated for scale up/down. Defaults to 10s."', args=[d.arg(name='scanInterval', type=d.T.string)]),
        withScanInterval(scanInterval): { scanInterval: scanInterval },
        '#withSkipNodesWithLocalStorage':: d.fn(help='"If true cluster autoscaler will never delete nodes with pods with local storage, for example, EmptyDir or HostPath. Defaults to true."', args=[d.arg(name='skipNodesWithLocalStorage', type=d.T.boolean)]),
        withSkipNodesWithLocalStorage(skipNodesWithLocalStorage): { skipNodesWithLocalStorage: skipNodesWithLocalStorage },
        '#withSkipNodesWithSystemPods':: d.fn(help='"If true cluster autoscaler will never delete nodes with pods from kube-system (except for DaemonSet or mirror pods). Defaults to true."', args=[d.arg(name='skipNodesWithSystemPods', type=d.T.boolean)]),
        withSkipNodesWithSystemPods(skipNodesWithSystemPods): { skipNodesWithSystemPods: skipNodesWithSystemPods },
      },
      '#azureActiveDirectoryRoleBasedAccessControl':: d.obj(help='"- A azure_active_directory_role_based_access_control block as defined below."'),
      azureActiveDirectoryRoleBasedAccessControl: {
        '#serverAppSecretSecretRef':: d.obj(help='"The Server Secret of an Azure Active Directory Application."'),
        serverAppSecretSecretRef: {
          '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { serverAppSecretSecretRef+: { key: key } },
          '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { serverAppSecretSecretRef+: { name: name } },
          '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { serverAppSecretSecretRef+: { namespace: namespace } },
        },
        '#withAdminGroupObjectIds':: d.fn(help='"A list of Object IDs of Azure Active Directory Groups which should have Admin Role on the Cluster."', args=[d.arg(name='adminGroupObjectIds', type=d.T.array)]),
        withAdminGroupObjectIds(adminGroupObjectIds): { adminGroupObjectIds: if std.isArray(v=adminGroupObjectIds) then adminGroupObjectIds else [adminGroupObjectIds] },
        '#withAdminGroupObjectIdsMixin':: d.fn(help='"A list of Object IDs of Azure Active Directory Groups which should have Admin Role on the Cluster."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='adminGroupObjectIds', type=d.T.array)]),
        withAdminGroupObjectIdsMixin(adminGroupObjectIds): { adminGroupObjectIds+: if std.isArray(v=adminGroupObjectIds) then adminGroupObjectIds else [adminGroupObjectIds] },
        '#withAzureRbacEnabled':: d.fn(help='"Is Role Based Access Control based on Azure AD enabled?"', args=[d.arg(name='azureRbacEnabled', type=d.T.boolean)]),
        withAzureRbacEnabled(azureRbacEnabled): { azureRbacEnabled: azureRbacEnabled },
        '#withClientAppId':: d.fn(help='"The Client ID of an Azure Active Directory Application."', args=[d.arg(name='clientAppId', type=d.T.string)]),
        withClientAppId(clientAppId): { clientAppId: clientAppId },
        '#withManaged':: d.fn(help='"Is the Azure Active Directory integration Managed, meaning that Azure will create/manage the Service Principal used for integration."', args=[d.arg(name='managed', type=d.T.boolean)]),
        withManaged(managed): { managed: managed },
        '#withServerAppId':: d.fn(help='"The Server ID of an Azure Active Directory Application."', args=[d.arg(name='serverAppId', type=d.T.string)]),
        withServerAppId(serverAppId): { serverAppId: serverAppId },
        '#withTenantId':: d.fn(help="\"The Tenant ID used for Azure Active Directory Application. If this isn't specified the Tenant ID of the current Subscription is used.\"", args=[d.arg(name='tenantId', type=d.T.string)]),
        withTenantId(tenantId): { tenantId: tenantId },
      },
      '#defaultNodePool':: d.obj(help='"A default_node_pool block as defined below."'),
      defaultNodePool: {
        '#kubeletConfig':: d.obj(help='"A kubelet_config block as defined below."'),
        kubeletConfig: {
          '#withAllowedUnsafeSysctls':: d.fn(help='"Specifies the allow list of unsafe sysctls command or patterns (ending in *). Changing this forces a new resource to be created."', args=[d.arg(name='allowedUnsafeSysctls', type=d.T.array)]),
          withAllowedUnsafeSysctls(allowedUnsafeSysctls): { allowedUnsafeSysctls: if std.isArray(v=allowedUnsafeSysctls) then allowedUnsafeSysctls else [allowedUnsafeSysctls] },
          '#withAllowedUnsafeSysctlsMixin':: d.fn(help='"Specifies the allow list of unsafe sysctls command or patterns (ending in *). Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='allowedUnsafeSysctls', type=d.T.array)]),
          withAllowedUnsafeSysctlsMixin(allowedUnsafeSysctls): { allowedUnsafeSysctls+: if std.isArray(v=allowedUnsafeSysctls) then allowedUnsafeSysctls else [allowedUnsafeSysctls] },
          '#withContainerLogMaxLine':: d.fn(help='"Specifies the maximum number of container log files that can be present for a container. must be at least 2. Changing this forces a new resource to be created."', args=[d.arg(name='containerLogMaxLine', type=d.T.number)]),
          withContainerLogMaxLine(containerLogMaxLine): { containerLogMaxLine: containerLogMaxLine },
          '#withContainerLogMaxSizeMb':: d.fn(help='"Specifies the maximum size (e.g. 10MB) of container log file before it is rotated. Changing this forces a new resource to be created."', args=[d.arg(name='containerLogMaxSizeMb', type=d.T.number)]),
          withContainerLogMaxSizeMb(containerLogMaxSizeMb): { containerLogMaxSizeMb: containerLogMaxSizeMb },
          '#withCpuCfsQuotaEnabled':: d.fn(help='"Is CPU CFS quota enforcement for containers enabled? Changing this forces a new resource to be created."', args=[d.arg(name='cpuCfsQuotaEnabled', type=d.T.boolean)]),
          withCpuCfsQuotaEnabled(cpuCfsQuotaEnabled): { cpuCfsQuotaEnabled: cpuCfsQuotaEnabled },
          '#withCpuCfsQuotaPeriod':: d.fn(help='"Specifies the CPU CFS quota period value. Changing this forces a new resource to be created."', args=[d.arg(name='cpuCfsQuotaPeriod', type=d.T.string)]),
          withCpuCfsQuotaPeriod(cpuCfsQuotaPeriod): { cpuCfsQuotaPeriod: cpuCfsQuotaPeriod },
          '#withCpuManagerPolicy':: d.fn(help='"Specifies the CPU Manager policy to use. Possible values are none and static, Changing this forces a new resource to be created."', args=[d.arg(name='cpuManagerPolicy', type=d.T.string)]),
          withCpuManagerPolicy(cpuManagerPolicy): { cpuManagerPolicy: cpuManagerPolicy },
          '#withImageGcHighThreshold':: d.fn(help='"Specifies the percent of disk usage above which image garbage collection is always run. Must be between 0 and 100. Changing this forces a new resource to be created."', args=[d.arg(name='imageGcHighThreshold', type=d.T.number)]),
          withImageGcHighThreshold(imageGcHighThreshold): { imageGcHighThreshold: imageGcHighThreshold },
          '#withImageGcLowThreshold':: d.fn(help='"Specifies the percent of disk usage lower than which image garbage collection is never run. Must be between 0 and 100. Changing this forces a new resource to be created."', args=[d.arg(name='imageGcLowThreshold', type=d.T.number)]),
          withImageGcLowThreshold(imageGcLowThreshold): { imageGcLowThreshold: imageGcLowThreshold },
          '#withPodMaxPid':: d.fn(help='"Specifies the maximum number of processes per pod. Changing this forces a new resource to be created."', args=[d.arg(name='podMaxPid', type=d.T.number)]),
          withPodMaxPid(podMaxPid): { podMaxPid: podMaxPid },
          '#withTopologyManagerPolicy':: d.fn(help='"Specifies the Topology Manager policy to use. Possible values are none, best-effort, restricted or single-numa-node. Changing this forces a new resource to be created."', args=[d.arg(name='topologyManagerPolicy', type=d.T.string)]),
          withTopologyManagerPolicy(topologyManagerPolicy): { topologyManagerPolicy: topologyManagerPolicy },
        },
        '#linuxOsConfig':: d.obj(help='"A linux_os_config block as defined below."'),
        linuxOsConfig: {
          '#sysctlConfig':: d.obj(help='"A sysctl_config block as defined below. Changing this forces a new resource to be created."'),
          sysctlConfig: {
            '#withFsAioMaxNr':: d.fn(help='"The sysctl setting fs.aio-max-nr. Must be between 65536 and 6553500. Changing this forces a new resource to be created."', args=[d.arg(name='fsAioMaxNr', type=d.T.number)]),
            withFsAioMaxNr(fsAioMaxNr): { fsAioMaxNr: fsAioMaxNr },
            '#withFsFileMax':: d.fn(help='"The sysctl setting fs.file-max. Must be between 8192 and 12000500. Changing this forces a new resource to be created."', args=[d.arg(name='fsFileMax', type=d.T.number)]),
            withFsFileMax(fsFileMax): { fsFileMax: fsFileMax },
            '#withFsInotifyMaxUserWatches':: d.fn(help='"The sysctl setting fs.inotify.max_user_watches. Must be between 781250 and 2097152. Changing this forces a new resource to be created."', args=[d.arg(name='fsInotifyMaxUserWatches', type=d.T.number)]),
            withFsInotifyMaxUserWatches(fsInotifyMaxUserWatches): { fsInotifyMaxUserWatches: fsInotifyMaxUserWatches },
            '#withFsNrOpen':: d.fn(help='"The sysctl setting fs.nr_open. Must be between 8192 and 20000500. Changing this forces a new resource to be created."', args=[d.arg(name='fsNrOpen', type=d.T.number)]),
            withFsNrOpen(fsNrOpen): { fsNrOpen: fsNrOpen },
            '#withKernelThreadsMax':: d.fn(help='"The sysctl setting kernel.threads-max. Must be between 20 and 513785. Changing this forces a new resource to be created."', args=[d.arg(name='kernelThreadsMax', type=d.T.number)]),
            withKernelThreadsMax(kernelThreadsMax): { kernelThreadsMax: kernelThreadsMax },
            '#withNetCoreNetdevMaxBacklog':: d.fn(help='"The sysctl setting net.core.netdev_max_backlog. Must be between 1000 and 3240000. Changing this forces a new resource to be created."', args=[d.arg(name='netCoreNetdevMaxBacklog', type=d.T.number)]),
            withNetCoreNetdevMaxBacklog(netCoreNetdevMaxBacklog): { netCoreNetdevMaxBacklog: netCoreNetdevMaxBacklog },
            '#withNetCoreOptmemMax':: d.fn(help='"The sysctl setting net.core.optmem_max. Must be between 20480 and 4194304. Changing this forces a new resource to be created."', args=[d.arg(name='netCoreOptmemMax', type=d.T.number)]),
            withNetCoreOptmemMax(netCoreOptmemMax): { netCoreOptmemMax: netCoreOptmemMax },
            '#withNetCoreRmemDefault':: d.fn(help='"The sysctl setting net.core.rmem_default. Must be between 212992 and 134217728. Changing this forces a new resource to be created."', args=[d.arg(name='netCoreRmemDefault', type=d.T.number)]),
            withNetCoreRmemDefault(netCoreRmemDefault): { netCoreRmemDefault: netCoreRmemDefault },
            '#withNetCoreRmemMax':: d.fn(help='"The sysctl setting net.core.rmem_max. Must be between 212992 and 134217728. Changing this forces a new resource to be created."', args=[d.arg(name='netCoreRmemMax', type=d.T.number)]),
            withNetCoreRmemMax(netCoreRmemMax): { netCoreRmemMax: netCoreRmemMax },
            '#withNetCoreSomaxconn':: d.fn(help='"The sysctl setting net.core.somaxconn. Must be between 4096 and 3240000. Changing this forces a new resource to be created."', args=[d.arg(name='netCoreSomaxconn', type=d.T.number)]),
            withNetCoreSomaxconn(netCoreSomaxconn): { netCoreSomaxconn: netCoreSomaxconn },
            '#withNetCoreWmemDefault':: d.fn(help='"The sysctl setting net.core.wmem_default. Must be between 212992 and 134217728. Changing this forces a new resource to be created."', args=[d.arg(name='netCoreWmemDefault', type=d.T.number)]),
            withNetCoreWmemDefault(netCoreWmemDefault): { netCoreWmemDefault: netCoreWmemDefault },
            '#withNetCoreWmemMax':: d.fn(help='"The sysctl setting net.core.wmem_max. Must be between 212992 and 134217728. Changing this forces a new resource to be created."', args=[d.arg(name='netCoreWmemMax', type=d.T.number)]),
            withNetCoreWmemMax(netCoreWmemMax): { netCoreWmemMax: netCoreWmemMax },
            '#withNetIpv4IpLocalPortRangeMax':: d.fn(help='"The sysctl setting net.ipv4.ip_local_port_range max value. Must be between 1024 and 60999. Changing this forces a new resource to be created."', args=[d.arg(name='netIpv4IpLocalPortRangeMax', type=d.T.number)]),
            withNetIpv4IpLocalPortRangeMax(netIpv4IpLocalPortRangeMax): { netIpv4IpLocalPortRangeMax: netIpv4IpLocalPortRangeMax },
            '#withNetIpv4IpLocalPortRangeMin':: d.fn(help='"The sysctl setting net.ipv4.ip_local_port_range min value. Must be between 1024 and 60999. Changing this forces a new resource to be created."', args=[d.arg(name='netIpv4IpLocalPortRangeMin', type=d.T.number)]),
            withNetIpv4IpLocalPortRangeMin(netIpv4IpLocalPortRangeMin): { netIpv4IpLocalPortRangeMin: netIpv4IpLocalPortRangeMin },
            '#withNetIpv4NeighDefaultGcThresh1':: d.fn(help='"The sysctl setting net.ipv4.neigh.default.gc_thresh1. Must be between 128 and 80000. Changing this forces a new resource to be created."', args=[d.arg(name='netIpv4NeighDefaultGcThresh1', type=d.T.number)]),
            withNetIpv4NeighDefaultGcThresh1(netIpv4NeighDefaultGcThresh1): { netIpv4NeighDefaultGcThresh1: netIpv4NeighDefaultGcThresh1 },
            '#withNetIpv4NeighDefaultGcThresh2':: d.fn(help='"The sysctl setting net.ipv4.neigh.default.gc_thresh2. Must be between 512 and 90000. Changing this forces a new resource to be created."', args=[d.arg(name='netIpv4NeighDefaultGcThresh2', type=d.T.number)]),
            withNetIpv4NeighDefaultGcThresh2(netIpv4NeighDefaultGcThresh2): { netIpv4NeighDefaultGcThresh2: netIpv4NeighDefaultGcThresh2 },
            '#withNetIpv4NeighDefaultGcThresh3':: d.fn(help='"The sysctl setting net.ipv4.neigh.default.gc_thresh3. Must be between 1024 and 100000. Changing this forces a new resource to be created."', args=[d.arg(name='netIpv4NeighDefaultGcThresh3', type=d.T.number)]),
            withNetIpv4NeighDefaultGcThresh3(netIpv4NeighDefaultGcThresh3): { netIpv4NeighDefaultGcThresh3: netIpv4NeighDefaultGcThresh3 },
            '#withNetIpv4TcpFinTimeout':: d.fn(help='"The sysctl setting net.ipv4.tcp_fin_timeout. Must be between 5 and 120. Changing this forces a new resource to be created."', args=[d.arg(name='netIpv4TcpFinTimeout', type=d.T.number)]),
            withNetIpv4TcpFinTimeout(netIpv4TcpFinTimeout): { netIpv4TcpFinTimeout: netIpv4TcpFinTimeout },
            '#withNetIpv4TcpKeepaliveIntvl':: d.fn(help='"The sysctl setting net.ipv4.tcp_keepalive_intvl. Must be between 10 and 75. Changing this forces a new resource to be created."', args=[d.arg(name='netIpv4TcpKeepaliveIntvl', type=d.T.number)]),
            withNetIpv4TcpKeepaliveIntvl(netIpv4TcpKeepaliveIntvl): { netIpv4TcpKeepaliveIntvl: netIpv4TcpKeepaliveIntvl },
            '#withNetIpv4TcpKeepaliveProbes':: d.fn(help='"The sysctl setting net.ipv4.tcp_keepalive_probes. Must be between 1 and 15. Changing this forces a new resource to be created."', args=[d.arg(name='netIpv4TcpKeepaliveProbes', type=d.T.number)]),
            withNetIpv4TcpKeepaliveProbes(netIpv4TcpKeepaliveProbes): { netIpv4TcpKeepaliveProbes: netIpv4TcpKeepaliveProbes },
            '#withNetIpv4TcpKeepaliveTime':: d.fn(help='"The sysctl setting net.ipv4.tcp_keepalive_time. Must be between 30 and 432000. Changing this forces a new resource to be created."', args=[d.arg(name='netIpv4TcpKeepaliveTime', type=d.T.number)]),
            withNetIpv4TcpKeepaliveTime(netIpv4TcpKeepaliveTime): { netIpv4TcpKeepaliveTime: netIpv4TcpKeepaliveTime },
            '#withNetIpv4TcpMaxSynBacklog':: d.fn(help='"The sysctl setting net.ipv4.tcp_max_syn_backlog. Must be between 128 and 3240000. Changing this forces a new resource to be created."', args=[d.arg(name='netIpv4TcpMaxSynBacklog', type=d.T.number)]),
            withNetIpv4TcpMaxSynBacklog(netIpv4TcpMaxSynBacklog): { netIpv4TcpMaxSynBacklog: netIpv4TcpMaxSynBacklog },
            '#withNetIpv4TcpMaxTwBuckets':: d.fn(help='"The sysctl setting net.ipv4.tcp_max_tw_buckets. Must be between 8000 and 1440000. Changing this forces a new resource to be created."', args=[d.arg(name='netIpv4TcpMaxTwBuckets', type=d.T.number)]),
            withNetIpv4TcpMaxTwBuckets(netIpv4TcpMaxTwBuckets): { netIpv4TcpMaxTwBuckets: netIpv4TcpMaxTwBuckets },
            '#withNetIpv4TcpTwReuse':: d.fn(help='"The sysctl setting net.ipv4.tcp_tw_reuse. Changing this forces a new resource to be created."', args=[d.arg(name='netIpv4TcpTwReuse', type=d.T.boolean)]),
            withNetIpv4TcpTwReuse(netIpv4TcpTwReuse): { netIpv4TcpTwReuse: netIpv4TcpTwReuse },
            '#withNetNetfilterNfConntrackBuckets':: d.fn(help='"The sysctl setting net.netfilter.nf_conntrack_buckets. Must be between 65536 and 147456. Changing this forces a new resource to be created."', args=[d.arg(name='netNetfilterNfConntrackBuckets', type=d.T.number)]),
            withNetNetfilterNfConntrackBuckets(netNetfilterNfConntrackBuckets): { netNetfilterNfConntrackBuckets: netNetfilterNfConntrackBuckets },
            '#withNetNetfilterNfConntrackMax':: d.fn(help='"The sysctl setting net.netfilter.nf_conntrack_max. Must be between 131072 and 1048576. Changing this forces a new resource to be created."', args=[d.arg(name='netNetfilterNfConntrackMax', type=d.T.number)]),
            withNetNetfilterNfConntrackMax(netNetfilterNfConntrackMax): { netNetfilterNfConntrackMax: netNetfilterNfConntrackMax },
            '#withVmMaxMapCount':: d.fn(help='"The sysctl setting vm.max_map_count. Must be between 65530 and 262144. Changing this forces a new resource to be created."', args=[d.arg(name='vmMaxMapCount', type=d.T.number)]),
            withVmMaxMapCount(vmMaxMapCount): { vmMaxMapCount: vmMaxMapCount },
            '#withVmSwappiness':: d.fn(help='"The sysctl setting vm.swappiness. Must be between 0 and 100. Changing this forces a new resource to be created."', args=[d.arg(name='vmSwappiness', type=d.T.number)]),
            withVmSwappiness(vmSwappiness): { vmSwappiness: vmSwappiness },
            '#withVmVfsCachePressure':: d.fn(help='"The sysctl setting vm.vfs_cache_pressure. Must be between 0 and 100. Changing this forces a new resource to be created."', args=[d.arg(name='vmVfsCachePressure', type=d.T.number)]),
            withVmVfsCachePressure(vmVfsCachePressure): { vmVfsCachePressure: vmVfsCachePressure },
          },
          '#withSwapFileSizeMb':: d.fn(help='"Specifies the size of swap file on each node in MB. Changing this forces a new resource to be created."', args=[d.arg(name='swapFileSizeMb', type=d.T.number)]),
          withSwapFileSizeMb(swapFileSizeMb): { swapFileSizeMb: swapFileSizeMb },
          '#withSysctlConfig':: d.fn(help='"A sysctl_config block as defined below. Changing this forces a new resource to be created."', args=[d.arg(name='sysctlConfig', type=d.T.array)]),
          withSysctlConfig(sysctlConfig): { sysctlConfig: if std.isArray(v=sysctlConfig) then sysctlConfig else [sysctlConfig] },
          '#withSysctlConfigMixin':: d.fn(help='"A sysctl_config block as defined below. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sysctlConfig', type=d.T.array)]),
          withSysctlConfigMixin(sysctlConfig): { sysctlConfig+: if std.isArray(v=sysctlConfig) then sysctlConfig else [sysctlConfig] },
          '#withTransparentHugePageDefrag':: d.fn(help='"specifies the defrag configuration for Transparent Huge Page. Possible values are always, defer, defer+madvise, madvise and never. Changing this forces a new resource to be created."', args=[d.arg(name='transparentHugePageDefrag', type=d.T.string)]),
          withTransparentHugePageDefrag(transparentHugePageDefrag): { transparentHugePageDefrag: transparentHugePageDefrag },
          '#withTransparentHugePageEnabled':: d.fn(help='"Specifies the Transparent Huge Page enabled configuration. Possible values are always, madvise and never. Changing this forces a new resource to be created."', args=[d.arg(name='transparentHugePageEnabled', type=d.T.string)]),
          withTransparentHugePageEnabled(transparentHugePageEnabled): { transparentHugePageEnabled: transparentHugePageEnabled },
        },
        '#podSubnetIdRef':: d.obj(help='"Reference to a Subnet in network to populate podSubnetId."'),
        podSubnetIdRef: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { podSubnetIdRef+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { podSubnetIdRef+: { policy+: { resolve: resolve } } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { podSubnetIdRef+: { name: name } },
        },
        '#podSubnetIdSelector':: d.obj(help='"Selector for a Subnet in network to populate podSubnetId."'),
        podSubnetIdSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { podSubnetIdSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { podSubnetIdSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference as the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { podSubnetIdSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { podSubnetIdSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { podSubnetIdSelector+: { matchLabels+: matchLabels } },
        },
        '#upgradeSettings':: d.obj(help='"A upgrade_settings block as documented below."'),
        upgradeSettings: {
          '#withMaxSurge':: d.fn(help='"The maximum number or percentage of nodes which will be added to the Node Pool size during an upgrade."', args=[d.arg(name='maxSurge', type=d.T.string)]),
          withMaxSurge(maxSurge): { maxSurge: maxSurge },
        },
        '#vnetSubnetIdRef':: d.obj(help='"Reference to a Subnet in network to populate vnetSubnetId."'),
        vnetSubnetIdRef: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { vnetSubnetIdRef+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { vnetSubnetIdRef+: { policy+: { resolve: resolve } } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { vnetSubnetIdRef+: { name: name } },
        },
        '#vnetSubnetIdSelector':: d.obj(help='"Selector for a Subnet in network to populate vnetSubnetId."'),
        vnetSubnetIdSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { vnetSubnetIdSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { vnetSubnetIdSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference as the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { vnetSubnetIdSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { vnetSubnetIdSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { vnetSubnetIdSelector+: { matchLabels+: matchLabels } },
        },
        '#withEnableAutoScaling':: d.fn(help='"Should the Kubernetes Auto Scaler be enabled for this Node Pool? Defaults to false."', args=[d.arg(name='enableAutoScaling', type=d.T.boolean)]),
        withEnableAutoScaling(enableAutoScaling): { enableAutoScaling: enableAutoScaling },
        '#withEnableHostEncryption':: d.fn(help='"Should the nodes in the Default Node Pool have host encryption enabled? Defaults to false."', args=[d.arg(name='enableHostEncryption', type=d.T.boolean)]),
        withEnableHostEncryption(enableHostEncryption): { enableHostEncryption: enableHostEncryption },
        '#withEnableNodePublicIp':: d.fn(help='"Should nodes in this Node Pool have a Public IP Address? Defaults to false. Changing this forces a new resource to be created."', args=[d.arg(name='enableNodePublicIp', type=d.T.boolean)]),
        withEnableNodePublicIp(enableNodePublicIp): { enableNodePublicIp: enableNodePublicIp },
        '#withFipsEnabled':: d.fn(help='"Should the nodes in this Node Pool have Federal Information Processing Standard enabled? Changing this forces a new resource to be created."', args=[d.arg(name='fipsEnabled', type=d.T.boolean)]),
        withFipsEnabled(fipsEnabled): { fipsEnabled: fipsEnabled },
        '#withKubeletConfig':: d.fn(help='"A kubelet_config block as defined below."', args=[d.arg(name='kubeletConfig', type=d.T.array)]),
        withKubeletConfig(kubeletConfig): { kubeletConfig: if std.isArray(v=kubeletConfig) then kubeletConfig else [kubeletConfig] },
        '#withKubeletConfigMixin':: d.fn(help='"A kubelet_config block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='kubeletConfig', type=d.T.array)]),
        withKubeletConfigMixin(kubeletConfig): { kubeletConfig+: if std.isArray(v=kubeletConfig) then kubeletConfig else [kubeletConfig] },
        '#withKubeletDiskType':: d.fn(help='"The type of disk used by kubelet. Possible values are OS and Temporary."', args=[d.arg(name='kubeletDiskType', type=d.T.string)]),
        withKubeletDiskType(kubeletDiskType): { kubeletDiskType: kubeletDiskType },
        '#withLinuxOsConfig':: d.fn(help='"A linux_os_config block as defined below."', args=[d.arg(name='linuxOsConfig', type=d.T.array)]),
        withLinuxOsConfig(linuxOsConfig): { linuxOsConfig: if std.isArray(v=linuxOsConfig) then linuxOsConfig else [linuxOsConfig] },
        '#withLinuxOsConfigMixin':: d.fn(help='"A linux_os_config block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='linuxOsConfig', type=d.T.array)]),
        withLinuxOsConfigMixin(linuxOsConfig): { linuxOsConfig+: if std.isArray(v=linuxOsConfig) then linuxOsConfig else [linuxOsConfig] },
        '#withMaxCount':: d.fn(help='"The maximum number of nodes which should exist in this Node Pool. If specified this must be between 1 and 1000."', args=[d.arg(name='maxCount', type=d.T.number)]),
        withMaxCount(maxCount): { maxCount: maxCount },
        '#withMaxPods':: d.fn(help='"The maximum number of pods that can run on each agent. Changing this forces a new resource to be created."', args=[d.arg(name='maxPods', type=d.T.number)]),
        withMaxPods(maxPods): { maxPods: maxPods },
        '#withMinCount':: d.fn(help='"The minimum number of nodes which should exist in this Node Pool. If specified this must be between 1 and 1000."', args=[d.arg(name='minCount', type=d.T.number)]),
        withMinCount(minCount): { minCount: minCount },
        '#withName':: d.fn(help='"The name which should be used for the default Kubernetes Node Pool. Changing this forces a new resource to be created."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withNodeCount':: d.fn(help='"The initial number of nodes which should exist in this Node Pool. If specified this must be between 1 and 1000 and between min_count and max_count."', args=[d.arg(name='nodeCount', type=d.T.number)]),
        withNodeCount(nodeCount): { nodeCount: nodeCount },
        '#withNodeLabels':: d.fn(help='"A map of Kubernetes labels which should be applied to nodes in the Default Node Pool."', args=[d.arg(name='nodeLabels', type=d.T.object)]),
        withNodeLabels(nodeLabels): { nodeLabels: nodeLabels },
        '#withNodeLabelsMixin':: d.fn(help='"A map of Kubernetes labels which should be applied to nodes in the Default Node Pool."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeLabels', type=d.T.object)]),
        withNodeLabelsMixin(nodeLabels): { nodeLabels+: nodeLabels },
        '#withNodePublicIpPrefixId':: d.fn(help='"Resource ID for the Public IP Addresses Prefix for the nodes in this Node Pool. enable_node_public_ip should be true. Changing this forces a new resource to be created."', args=[d.arg(name='nodePublicIpPrefixId', type=d.T.string)]),
        withNodePublicIpPrefixId(nodePublicIpPrefixId): { nodePublicIpPrefixId: nodePublicIpPrefixId },
        '#withNodeTaints':: d.fn(help='', args=[d.arg(name='nodeTaints', type=d.T.array)]),
        withNodeTaints(nodeTaints): { nodeTaints: if std.isArray(v=nodeTaints) then nodeTaints else [nodeTaints] },
        '#withNodeTaintsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeTaints', type=d.T.array)]),
        withNodeTaintsMixin(nodeTaints): { nodeTaints+: if std.isArray(v=nodeTaints) then nodeTaints else [nodeTaints] },
        '#withOnlyCriticalAddonsEnabled':: d.fn(help='"Enabling this option will taint default node pool with CriticalAddonsOnly=true:NoSchedule taint. Changing this forces a new resource to be created."', args=[d.arg(name='onlyCriticalAddonsEnabled', type=d.T.boolean)]),
        withOnlyCriticalAddonsEnabled(onlyCriticalAddonsEnabled): { onlyCriticalAddonsEnabled: onlyCriticalAddonsEnabled },
        '#withOrchestratorVersion':: d.fn(help="\"Version of Kubernetes used for the Agents. If not specified, the default node pool will be created with the version specified by kubernetes_version. If both are unspecified, the latest recommended version will be used at provisioning time (but won't auto-upgrade)\"", args=[d.arg(name='orchestratorVersion', type=d.T.string)]),
        withOrchestratorVersion(orchestratorVersion): { orchestratorVersion: orchestratorVersion },
        '#withOsDiskSizeGb':: d.fn(help='"The size of the OS Disk which should be used for each agent in the Node Pool. Changing this forces a new resource to be created."', args=[d.arg(name='osDiskSizeGb', type=d.T.number)]),
        withOsDiskSizeGb(osDiskSizeGb): { osDiskSizeGb: osDiskSizeGb },
        '#withOsDiskType':: d.fn(help='"The type of disk which should be used for the Operating System. Possible values are Ephemeral and Managed. Defaults to Managed. Changing this forces a new resource to be created."', args=[d.arg(name='osDiskType', type=d.T.string)]),
        withOsDiskType(osDiskType): { osDiskType: osDiskType },
        '#withOsSku':: d.fn(help='"OsSKU to be used to specify Linux OSType. Not applicable to Windows OSType. Possible values include: Ubuntu, CBLMariner. Defaults to Ubuntu. Changing this forces a new resource to be created."', args=[d.arg(name='osSku', type=d.T.string)]),
        withOsSku(osSku): { osSku: osSku },
        '#withPodSubnetId':: d.fn(help='"The ID of the Subnet where the pods in the default Node Pool should exist. Changing this forces a new resource to be created."', args=[d.arg(name='podSubnetId', type=d.T.string)]),
        withPodSubnetId(podSubnetId): { podSubnetId: podSubnetId },
        '#withProximityPlacementGroupId':: d.fn(help='"The Kubernetes Managed Cluster ID."', args=[d.arg(name='proximityPlacementGroupId', type=d.T.string)]),
        withProximityPlacementGroupId(proximityPlacementGroupId): { proximityPlacementGroupId: proximityPlacementGroupId },
        '#withTags':: d.fn(help='"A mapping of tags to assign to the Node Pool."', args=[d.arg(name='tags', type=d.T.object)]),
        withTags(tags): { tags: tags },
        '#withTagsMixin':: d.fn(help='"A mapping of tags to assign to the Node Pool."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tags', type=d.T.object)]),
        withTagsMixin(tags): { tags+: tags },
        '#withType':: d.fn(help='"The type of Node Pool which should be created. Possible values are AvailabilitySet and VirtualMachineScaleSets. Defaults to VirtualMachineScaleSets."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { type: type },
        '#withUltraSsdEnabled':: d.fn(help='"Used to specify whether the UltraSSD is enabled in the Default Node Pool. Defaults to false. See the documentation for more information."', args=[d.arg(name='ultraSsdEnabled', type=d.T.boolean)]),
        withUltraSsdEnabled(ultraSsdEnabled): { ultraSsdEnabled: ultraSsdEnabled },
        '#withUpgradeSettings':: d.fn(help='"A upgrade_settings block as documented below."', args=[d.arg(name='upgradeSettings', type=d.T.array)]),
        withUpgradeSettings(upgradeSettings): { upgradeSettings: if std.isArray(v=upgradeSettings) then upgradeSettings else [upgradeSettings] },
        '#withUpgradeSettingsMixin':: d.fn(help='"A upgrade_settings block as documented below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='upgradeSettings', type=d.T.array)]),
        withUpgradeSettingsMixin(upgradeSettings): { upgradeSettings+: if std.isArray(v=upgradeSettings) then upgradeSettings else [upgradeSettings] },
        '#withVmSize':: d.fn(help='"The size of the Virtual Machine, such as Standard_DS2_v2. Changing this forces a new resource to be created."', args=[d.arg(name='vmSize', type=d.T.string)]),
        withVmSize(vmSize): { vmSize: vmSize },
        '#withVnetSubnetId':: d.fn(help='"The ID of a Subnet where the Kubernetes Node Pool should exist. Changing this forces a new resource to be created."', args=[d.arg(name='vnetSubnetId', type=d.T.string)]),
        withVnetSubnetId(vnetSubnetId): { vnetSubnetId: vnetSubnetId },
        '#withZones':: d.fn(help='"Specifies a list of Availability Zones in which this Kubernetes Cluster should be located. Changing this forces a new Kubernetes Cluster to be created."', args=[d.arg(name='zones', type=d.T.array)]),
        withZones(zones): { zones: if std.isArray(v=zones) then zones else [zones] },
        '#withZonesMixin':: d.fn(help='"Specifies a list of Availability Zones in which this Kubernetes Cluster should be located. Changing this forces a new Kubernetes Cluster to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='zones', type=d.T.array)]),
        withZonesMixin(zones): { zones+: if std.isArray(v=zones) then zones else [zones] },
      },
      '#httpProxyConfig':: d.obj(help='"A http_proxy_config block as defined below."'),
      httpProxyConfig: {
        '#trustedCaSecretRef':: d.obj(help='"The base64 encoded alternative CA certificate content in PEM format."'),
        trustedCaSecretRef: {
          '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { trustedCaSecretRef+: { key: key } },
          '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { trustedCaSecretRef+: { name: name } },
          '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { trustedCaSecretRef+: { namespace: namespace } },
        },
        '#withHttpProxy':: d.fn(help='"The proxy address to be used when communicating over HTTP."', args=[d.arg(name='httpProxy', type=d.T.string)]),
        withHttpProxy(httpProxy): { httpProxy: httpProxy },
        '#withHttpsProxy':: d.fn(help='"The proxy address to be used when communicating over HTTPS."', args=[d.arg(name='httpsProxy', type=d.T.string)]),
        withHttpsProxy(httpsProxy): { httpsProxy: httpsProxy },
        '#withNoProxy':: d.fn(help='"The list of domains that will not use the proxy for communication."', args=[d.arg(name='noProxy', type=d.T.array)]),
        withNoProxy(noProxy): { noProxy: if std.isArray(v=noProxy) then noProxy else [noProxy] },
        '#withNoProxyMixin':: d.fn(help='"The list of domains that will not use the proxy for communication."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='noProxy', type=d.T.array)]),
        withNoProxyMixin(noProxy): { noProxy+: if std.isArray(v=noProxy) then noProxy else [noProxy] },
      },
      '#identity':: d.obj(help='"An identity block as defined below. One of either identity or service_principal must be specified."'),
      identity: {
        '#withIdentityIds':: d.fn(help='"Specifies a list of User Assigned Managed Identity IDs to be assigned to this Kubernetes Cluster."', args=[d.arg(name='identityIds', type=d.T.array)]),
        withIdentityIds(identityIds): { identityIds: if std.isArray(v=identityIds) then identityIds else [identityIds] },
        '#withIdentityIdsMixin':: d.fn(help='"Specifies a list of User Assigned Managed Identity IDs to be assigned to this Kubernetes Cluster."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='identityIds', type=d.T.array)]),
        withIdentityIdsMixin(identityIds): { identityIds+: if std.isArray(v=identityIds) then identityIds else [identityIds] },
        '#withType':: d.fn(help='"Specifies the type of Managed Service Identity that should be configured on this Kubernetes Cluster. Possible values are SystemAssigned, UserAssigned, SystemAssigned, UserAssigned (to enable both)."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { type: type },
      },
      '#ingressApplicationGateway':: d.obj(help='"A ingress_application_gateway block as defined below."'),
      ingressApplicationGateway: {
        '#subnetIdRef':: d.obj(help='"Reference to a Subnet in network to populate subnetId."'),
        subnetIdRef: {
          '#policy':: d.obj(help='"Policies for referencing."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetIdRef+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetIdRef+: { policy+: { resolve: resolve } } },
          },
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { subnetIdRef+: { name: name } },
        },
        '#subnetIdSelector':: d.obj(help='"Selector for a Subnet in network to populate subnetId."'),
        subnetIdSelector: {
          '#policy':: d.obj(help='"Policies for selection."'),
          policy: {
            '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
            withResolution(resolution): { subnetIdSelector+: { policy+: { resolution: resolution } } },
            '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
            withResolve(resolve): { subnetIdSelector+: { policy+: { resolve: resolve } } },
          },
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference as the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { subnetIdSelector+: { matchControllerRef: matchControllerRef } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { subnetIdSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { subnetIdSelector+: { matchLabels+: matchLabels } },
        },
        '#withGatewayId':: d.fn(help='"The ID of the Application Gateway to integrate with the ingress controller of this Kubernetes Cluster. See this page for further details."', args=[d.arg(name='gatewayId', type=d.T.string)]),
        withGatewayId(gatewayId): { gatewayId: gatewayId },
        '#withGatewayName':: d.fn(help='"The name of the Application Gateway to be used or created in the Nodepool Resource Group, which in turn will be integrated with the ingress controller of this Kubernetes Cluster. See this page for further details."', args=[d.arg(name='gatewayName', type=d.T.string)]),
        withGatewayName(gatewayName): { gatewayName: gatewayName },
        '#withSubnetCidr':: d.fn(help='"The subnet CIDR to be used to create an Application Gateway, which in turn will be integrated with the ingress controller of this Kubernetes Cluster. See this page for further details."', args=[d.arg(name='subnetCidr', type=d.T.string)]),
        withSubnetCidr(subnetCidr): { subnetCidr: subnetCidr },
        '#withSubnetId':: d.fn(help='"The ID of the subnet on which to create an Application Gateway, which in turn will be integrated with the ingress controller of this Kubernetes Cluster. See this page for further details."', args=[d.arg(name='subnetId', type=d.T.string)]),
        withSubnetId(subnetId): { subnetId: subnetId },
      },
      '#keyVaultSecretsProvider':: d.obj(help='"A key_vault_secrets_provider block as defined below. For more details, please visit Azure Keyvault Secrets Provider for AKS."'),
      keyVaultSecretsProvider: {
        '#withSecretRotationEnabled':: d.fn(help='"Is secret rotation enabled?"', args=[d.arg(name='secretRotationEnabled', type=d.T.boolean)]),
        withSecretRotationEnabled(secretRotationEnabled): { secretRotationEnabled: secretRotationEnabled },
        '#withSecretRotationInterval':: d.fn(help='"The interval to poll for secret rotation. This attribute is only set when secret_rotation is true and defaults to 2m."', args=[d.arg(name='secretRotationInterval', type=d.T.string)]),
        withSecretRotationInterval(secretRotationInterval): { secretRotationInterval: secretRotationInterval },
      },
      '#kubeletIdentity':: d.obj(help='"A kubelet_identity block as defined below. Changing this forces a new resource to be created."'),
      kubeletIdentity: {
        '#withClientId':: d.fn(help='"The Client ID of the user-defined Managed Identity to be assigned to the Kubelets. If not specified a Managed Identity is created automatically."', args=[d.arg(name='clientId', type=d.T.string)]),
        withClientId(clientId): { clientId: clientId },
        '#withObjectId':: d.fn(help='"The Object ID of the user-defined Managed Identity assigned to the Kubelets.If not specified a Managed Identity is created automatically."', args=[d.arg(name='objectId', type=d.T.string)]),
        withObjectId(objectId): { objectId: objectId },
        '#withUserAssignedIdentityId':: d.fn(help='"The ID of the User Assigned Identity assigned to the Kubelets. If not specified a Managed Identity is created automatically."', args=[d.arg(name='userAssignedIdentityId', type=d.T.string)]),
        withUserAssignedIdentityId(userAssignedIdentityId): { userAssignedIdentityId: userAssignedIdentityId },
      },
      '#linuxProfile':: d.obj(help='"A linux_profile block as defined below."'),
      linuxProfile: {
        '#sshKey':: d.obj(help='"An ssh_key block. Only one is currently allowed. Changing this forces a new resource to be created."'),
        sshKey: {
          '#withKeyData':: d.fn(help='"The Public SSH Key used to access the cluster. Changing this forces a new resource to be created."', args=[d.arg(name='keyData', type=d.T.string)]),
          withKeyData(keyData): { keyData: keyData },
        },
        '#withAdminUsername':: d.fn(help='"The Admin Username for the Cluster. Changing this forces a new resource to be created."', args=[d.arg(name='adminUsername', type=d.T.string)]),
        withAdminUsername(adminUsername): { adminUsername: adminUsername },
        '#withSshKey':: d.fn(help='"An ssh_key block. Only one is currently allowed. Changing this forces a new resource to be created."', args=[d.arg(name='sshKey', type=d.T.array)]),
        withSshKey(sshKey): { sshKey: if std.isArray(v=sshKey) then sshKey else [sshKey] },
        '#withSshKeyMixin':: d.fn(help='"An ssh_key block. Only one is currently allowed. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sshKey', type=d.T.array)]),
        withSshKeyMixin(sshKey): { sshKey+: if std.isArray(v=sshKey) then sshKey else [sshKey] },
      },
      '#maintenanceWindow':: d.obj(help='"A maintenance_window block as defined below."'),
      maintenanceWindow: {
        '#allowed':: d.obj(help='"One or more allowed block as defined below."'),
        allowed: {
          '#withDay':: d.fn(help='"A day in a week. Possible values are Sunday, Monday, Tuesday, Wednesday, Thursday, Friday and Saturday."', args=[d.arg(name='day', type=d.T.string)]),
          withDay(day): { day: day },
          '#withHours':: d.fn(help='"An array of hour slots in a day. For example, specifying 1 will allow maintenance from 1:00am to 2:00am. Specifying 1, 2 will allow maintenance from 1:00am to 3:00m. Possible values are between 0 and 23."', args=[d.arg(name='hours', type=d.T.array)]),
          withHours(hours): { hours: if std.isArray(v=hours) then hours else [hours] },
          '#withHoursMixin':: d.fn(help='"An array of hour slots in a day. For example, specifying 1 will allow maintenance from 1:00am to 2:00am. Specifying 1, 2 will allow maintenance from 1:00am to 3:00m. Possible values are between 0 and 23."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='hours', type=d.T.array)]),
          withHoursMixin(hours): { hours+: if std.isArray(v=hours) then hours else [hours] },
        },
        '#notAllowed':: d.obj(help='"One or more not_allowed block as defined below."'),
        notAllowed: {
          '#withEnd':: d.fn(help='"The end of a time span, formatted as an RFC3339 string."', args=[d.arg(name='end', type=d.T.string)]),
          withEnd(end): { end: end },
          '#withStart':: d.fn(help='"The start of a time span, formatted as an RFC3339 string."', args=[d.arg(name='start', type=d.T.string)]),
          withStart(start): { start: start },
        },
        '#withAllowed':: d.fn(help='"One or more allowed block as defined below."', args=[d.arg(name='allowed', type=d.T.array)]),
        withAllowed(allowed): { allowed: if std.isArray(v=allowed) then allowed else [allowed] },
        '#withAllowedMixin':: d.fn(help='"One or more allowed block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='allowed', type=d.T.array)]),
        withAllowedMixin(allowed): { allowed+: if std.isArray(v=allowed) then allowed else [allowed] },
        '#withNotAllowed':: d.fn(help='"One or more not_allowed block as defined below."', args=[d.arg(name='notAllowed', type=d.T.array)]),
        withNotAllowed(notAllowed): { notAllowed: if std.isArray(v=notAllowed) then notAllowed else [notAllowed] },
        '#withNotAllowedMixin':: d.fn(help='"One or more not_allowed block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='notAllowed', type=d.T.array)]),
        withNotAllowedMixin(notAllowed): { notAllowed+: if std.isArray(v=notAllowed) then notAllowed else [notAllowed] },
      },
      '#microsoftDefender':: d.obj(help='"A microsoft_defender block as defined below."'),
      microsoftDefender: {
        '#withLogAnalyticsWorkspaceId':: d.fn(help='"Specifies the ID of the Log Analytics Workspace where the audit logs collected by Microsoft Defender should be sent to."', args=[d.arg(name='logAnalyticsWorkspaceId', type=d.T.string)]),
        withLogAnalyticsWorkspaceId(logAnalyticsWorkspaceId): { logAnalyticsWorkspaceId: logAnalyticsWorkspaceId },
      },
      '#networkProfile':: d.obj(help='"A network_profile block as defined below."'),
      networkProfile: {
        '#loadBalancerProfile':: d.obj(help='"A load_balancer_profile block. This can only be specified when load_balancer_sku is set to standard."'),
        loadBalancerProfile: {
          '#withIdleTimeoutInMinutes':: d.fn(help='"Desired outbound flow idle timeout in minutes for the cluster load balancer. Must be between 4 and 120 inclusive. Defaults to 4."', args=[d.arg(name='idleTimeoutInMinutes', type=d.T.number)]),
          withIdleTimeoutInMinutes(idleTimeoutInMinutes): { idleTimeoutInMinutes: idleTimeoutInMinutes },
          '#withManagedOutboundIpCount':: d.fn(help='"Count of desired managed outbound IPs for the cluster load balancer. Must be between 1 and 100 inclusive."', args=[d.arg(name='managedOutboundIpCount', type=d.T.number)]),
          withManagedOutboundIpCount(managedOutboundIpCount): { managedOutboundIpCount: managedOutboundIpCount },
          '#withOutboundIpAddressIds':: d.fn(help='"The ID of the Public IP Addresses which should be used for outbound communication for the cluster load balancer."', args=[d.arg(name='outboundIpAddressIds', type=d.T.array)]),
          withOutboundIpAddressIds(outboundIpAddressIds): { outboundIpAddressIds: if std.isArray(v=outboundIpAddressIds) then outboundIpAddressIds else [outboundIpAddressIds] },
          '#withOutboundIpAddressIdsMixin':: d.fn(help='"The ID of the Public IP Addresses which should be used for outbound communication for the cluster load balancer."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='outboundIpAddressIds', type=d.T.array)]),
          withOutboundIpAddressIdsMixin(outboundIpAddressIds): { outboundIpAddressIds+: if std.isArray(v=outboundIpAddressIds) then outboundIpAddressIds else [outboundIpAddressIds] },
          '#withOutboundIpPrefixIds':: d.fn(help='"The ID of the outbound Public IP Address Prefixes which should be used for the cluster load balancer."', args=[d.arg(name='outboundIpPrefixIds', type=d.T.array)]),
          withOutboundIpPrefixIds(outboundIpPrefixIds): { outboundIpPrefixIds: if std.isArray(v=outboundIpPrefixIds) then outboundIpPrefixIds else [outboundIpPrefixIds] },
          '#withOutboundIpPrefixIdsMixin':: d.fn(help='"The ID of the outbound Public IP Address Prefixes which should be used for the cluster load balancer."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='outboundIpPrefixIds', type=d.T.array)]),
          withOutboundIpPrefixIdsMixin(outboundIpPrefixIds): { outboundIpPrefixIds+: if std.isArray(v=outboundIpPrefixIds) then outboundIpPrefixIds else [outboundIpPrefixIds] },
          '#withOutboundPortsAllocated':: d.fn(help='"Number of desired SNAT port for each VM in the clusters load balancer. Must be between 0 and 64000 inclusive. Defaults to 0."', args=[d.arg(name='outboundPortsAllocated', type=d.T.number)]),
          withOutboundPortsAllocated(outboundPortsAllocated): { outboundPortsAllocated: outboundPortsAllocated },
        },
        '#natGatewayProfile':: d.obj(help='"A nat_gateway_profile block. This can only be specified when load_balancer_sku is set to standard and outbound_type is set to managedNATGateway or userAssignedNATGateway."'),
        natGatewayProfile: {
          '#withIdleTimeoutInMinutes':: d.fn(help='"Desired outbound flow idle timeout in minutes for the cluster load balancer. Must be between 4 and 120 inclusive. Defaults to 4."', args=[d.arg(name='idleTimeoutInMinutes', type=d.T.number)]),
          withIdleTimeoutInMinutes(idleTimeoutInMinutes): { idleTimeoutInMinutes: idleTimeoutInMinutes },
          '#withManagedOutboundIpCount':: d.fn(help='"Count of desired managed outbound IPs for the cluster load balancer. Must be between 1 and 100 inclusive."', args=[d.arg(name='managedOutboundIpCount', type=d.T.number)]),
          withManagedOutboundIpCount(managedOutboundIpCount): { managedOutboundIpCount: managedOutboundIpCount },
        },
        '#withDnsServiceIp':: d.fn(help='"IP address within the Kubernetes service address range that will be used by cluster service discovery (kube-dns). Changing this forces a new resource to be created."', args=[d.arg(name='dnsServiceIp', type=d.T.string)]),
        withDnsServiceIp(dnsServiceIp): { dnsServiceIp: dnsServiceIp },
        '#withDockerBridgeCidr':: d.fn(help='"IP address (in CIDR notation) used as the Docker bridge IP address on nodes. Changing this forces a new resource to be created."', args=[d.arg(name='dockerBridgeCidr', type=d.T.string)]),
        withDockerBridgeCidr(dockerBridgeCidr): { dockerBridgeCidr: dockerBridgeCidr },
        '#withIpVersions':: d.fn(help='"Specifies a list of IP versions the Kubernetes Cluster will use to assign IP addresses to its nodes and pods. Possible values are IPv4 and/or IPv6. IPv4 must always be specified. Changing this forces a new resource to be created."', args=[d.arg(name='ipVersions', type=d.T.array)]),
        withIpVersions(ipVersions): { ipVersions: if std.isArray(v=ipVersions) then ipVersions else [ipVersions] },
        '#withIpVersionsMixin':: d.fn(help='"Specifies a list of IP versions the Kubernetes Cluster will use to assign IP addresses to its nodes and pods. Possible values are IPv4 and/or IPv6. IPv4 must always be specified. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ipVersions', type=d.T.array)]),
        withIpVersionsMixin(ipVersions): { ipVersions+: if std.isArray(v=ipVersions) then ipVersions else [ipVersions] },
        '#withLoadBalancerProfile':: d.fn(help='"A load_balancer_profile block. This can only be specified when load_balancer_sku is set to standard."', args=[d.arg(name='loadBalancerProfile', type=d.T.array)]),
        withLoadBalancerProfile(loadBalancerProfile): { loadBalancerProfile: if std.isArray(v=loadBalancerProfile) then loadBalancerProfile else [loadBalancerProfile] },
        '#withLoadBalancerProfileMixin':: d.fn(help='"A load_balancer_profile block. This can only be specified when load_balancer_sku is set to standard."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='loadBalancerProfile', type=d.T.array)]),
        withLoadBalancerProfileMixin(loadBalancerProfile): { loadBalancerProfile+: if std.isArray(v=loadBalancerProfile) then loadBalancerProfile else [loadBalancerProfile] },
        '#withLoadBalancerSku':: d.fn(help='"Specifies the SKU of the Load Balancer used for this Kubernetes Cluster. Possible values are basic and standard. Defaults to standard."', args=[d.arg(name='loadBalancerSku', type=d.T.string)]),
        withLoadBalancerSku(loadBalancerSku): { loadBalancerSku: loadBalancerSku },
        '#withNatGatewayProfile':: d.fn(help='"A nat_gateway_profile block. This can only be specified when load_balancer_sku is set to standard and outbound_type is set to managedNATGateway or userAssignedNATGateway."', args=[d.arg(name='natGatewayProfile', type=d.T.array)]),
        withNatGatewayProfile(natGatewayProfile): { natGatewayProfile: if std.isArray(v=natGatewayProfile) then natGatewayProfile else [natGatewayProfile] },
        '#withNatGatewayProfileMixin':: d.fn(help='"A nat_gateway_profile block. This can only be specified when load_balancer_sku is set to standard and outbound_type is set to managedNATGateway or userAssignedNATGateway."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='natGatewayProfile', type=d.T.array)]),
        withNatGatewayProfileMixin(natGatewayProfile): { natGatewayProfile+: if std.isArray(v=natGatewayProfile) then natGatewayProfile else [natGatewayProfile] },
        '#withNetworkMode':: d.fn(help='"Network mode to be used with Azure CNI. Possible values are bridge and transparent. Changing this forces a new resource to be created."', args=[d.arg(name='networkMode', type=d.T.string)]),
        withNetworkMode(networkMode): { networkMode: networkMode },
        '#withNetworkPlugin':: d.fn(help='"Network plugin to use for networking. Currently supported values are azure, kubenet and none. Changing this forces a new resource to be created."', args=[d.arg(name='networkPlugin', type=d.T.string)]),
        withNetworkPlugin(networkPlugin): { networkPlugin: networkPlugin },
        '#withNetworkPolicy':: d.fn(help='"Sets up network policy to be used with Azure CNI. Network policy allows us to control the traffic flow between pods. Currently supported values are calico and azure. Changing this forces a new resource to be created."', args=[d.arg(name='networkPolicy', type=d.T.string)]),
        withNetworkPolicy(networkPolicy): { networkPolicy: networkPolicy },
        '#withOutboundType':: d.fn(help='"The outbound (egress) routing method which should be used for this Kubernetes Cluster. Possible values are loadBalancer, userDefinedRouting, managedNATGateway and userAssignedNATGateway. Defaults to loadBalancer."', args=[d.arg(name='outboundType', type=d.T.string)]),
        withOutboundType(outboundType): { outboundType: outboundType },
        '#withPodCidr':: d.fn(help='"The CIDR to use for pod IP addresses. This field can only be set when network_plugin is set to kubenet. Changing this forces a new resource to be created."', args=[d.arg(name='podCidr', type=d.T.string)]),
        withPodCidr(podCidr): { podCidr: podCidr },
        '#withServiceCidr':: d.fn(help='"The Network Range used by the Kubernetes service. Changing this forces a new resource to be created."', args=[d.arg(name='serviceCidr', type=d.T.string)]),
        withServiceCidr(serviceCidr): { serviceCidr: serviceCidr },
      },
      '#omsAgent':: d.obj(help='"A oms_agent block as defined below."'),
      omsAgent: {
        '#withLogAnalyticsWorkspaceId':: d.fn(help='"The ID of the Log Analytics Workspace which the OMS Agent should send data to."', args=[d.arg(name='logAnalyticsWorkspaceId', type=d.T.string)]),
        withLogAnalyticsWorkspaceId(logAnalyticsWorkspaceId): { logAnalyticsWorkspaceId: logAnalyticsWorkspaceId },
      },
      '#resourceGroupNameRef':: d.obj(help='"Reference to a ResourceGroup in azure to populate resourceGroupName."'),
      resourceGroupNameRef: {
        '#policy':: d.obj(help='"Policies for referencing."'),
        policy: {
          '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
          withResolution(resolution): { spec+: { forProvider+: { resourceGroupNameRef+: { policy+: { resolution: resolution } } } } },
          '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
          withResolve(resolve): { spec+: { forProvider+: { resourceGroupNameRef+: { policy+: { resolve: resolve } } } } },
        },
        '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { forProvider+: { resourceGroupNameRef+: { name: name } } } },
      },
      '#resourceGroupNameSelector':: d.obj(help='"Selector for a ResourceGroup in azure to populate resourceGroupName."'),
      resourceGroupNameSelector: {
        '#policy':: d.obj(help='"Policies for selection."'),
        policy: {
          '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
          withResolution(resolution): { spec+: { forProvider+: { resourceGroupNameSelector+: { policy+: { resolution: resolution } } } } },
          '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
          withResolve(resolve): { spec+: { forProvider+: { resourceGroupNameSelector+: { policy+: { resolve: resolve } } } } },
        },
        '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference as the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
        withMatchControllerRef(matchControllerRef): { spec+: { forProvider+: { resourceGroupNameSelector+: { matchControllerRef: matchControllerRef } } } },
        '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabels(matchLabels): { spec+: { forProvider+: { resourceGroupNameSelector+: { matchLabels: matchLabels } } } },
        '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabelsMixin(matchLabels): { spec+: { forProvider+: { resourceGroupNameSelector+: { matchLabels+: matchLabels } } } },
      },
      '#servicePrincipal':: d.obj(help='"A service_principal block as documented below. One of either identity or service_principal must be specified."'),
      servicePrincipal: {
        '#clientSecretSecretRef':: d.obj(help='"The Client Secret for the Service Principal."'),
        clientSecretSecretRef: {
          '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { clientSecretSecretRef+: { key: key } },
          '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { clientSecretSecretRef+: { name: name } },
          '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { clientSecretSecretRef+: { namespace: namespace } },
        },
        '#withClientId':: d.fn(help='"The Client ID for the Service Principal."', args=[d.arg(name='clientId', type=d.T.string)]),
        withClientId(clientId): { clientId: clientId },
      },
      '#windowsProfile':: d.obj(help='"A windows_profile block as defined below."'),
      windowsProfile: {
        '#adminPasswordSecretRef':: d.obj(help='"The Admin Password for Windows VMs. Length must be between 14 and 123 characters."'),
        adminPasswordSecretRef: {
          '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { adminPasswordSecretRef+: { key: key } },
          '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { adminPasswordSecretRef+: { name: name } },
          '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { adminPasswordSecretRef+: { namespace: namespace } },
        },
        '#withAdminUsername':: d.fn(help='"The Admin Username for Windows VMs."', args=[d.arg(name='adminUsername', type=d.T.string)]),
        withAdminUsername(adminUsername): { adminUsername: adminUsername },
        '#withLicense':: d.fn(help='"Specifies the type of on-premise license which should be used for Node Pool Windows Virtual Machine. At this time the only possible value is Windows_Server."', args=[d.arg(name='license', type=d.T.string)]),
        withLicense(license): { license: license },
      },
      '#withAciConnectorLinux':: d.fn(help='"A aci_connector_linux block as defined below. For more details, please visit Create and configure an AKS cluster to use virtual nodes."', args=[d.arg(name='aciConnectorLinux', type=d.T.array)]),
      withAciConnectorLinux(aciConnectorLinux): { spec+: { forProvider+: { aciConnectorLinux: if std.isArray(v=aciConnectorLinux) then aciConnectorLinux else [aciConnectorLinux] } } },
      '#withAciConnectorLinuxMixin':: d.fn(help='"A aci_connector_linux block as defined below. For more details, please visit Create and configure an AKS cluster to use virtual nodes."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='aciConnectorLinux', type=d.T.array)]),
      withAciConnectorLinuxMixin(aciConnectorLinux): { spec+: { forProvider+: { aciConnectorLinux+: if std.isArray(v=aciConnectorLinux) then aciConnectorLinux else [aciConnectorLinux] } } },
      '#withApiServerAuthorizedIpRanges':: d.fn(help='"The IP ranges to allow for incoming traffic to the server nodes."', args=[d.arg(name='apiServerAuthorizedIpRanges', type=d.T.array)]),
      withApiServerAuthorizedIpRanges(apiServerAuthorizedIpRanges): { spec+: { forProvider+: { apiServerAuthorizedIpRanges: if std.isArray(v=apiServerAuthorizedIpRanges) then apiServerAuthorizedIpRanges else [apiServerAuthorizedIpRanges] } } },
      '#withApiServerAuthorizedIpRangesMixin':: d.fn(help='"The IP ranges to allow for incoming traffic to the server nodes."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='apiServerAuthorizedIpRanges', type=d.T.array)]),
      withApiServerAuthorizedIpRangesMixin(apiServerAuthorizedIpRanges): { spec+: { forProvider+: { apiServerAuthorizedIpRanges+: if std.isArray(v=apiServerAuthorizedIpRanges) then apiServerAuthorizedIpRanges else [apiServerAuthorizedIpRanges] } } },
      '#withAutoScalerProfile':: d.fn(help='"A auto_scaler_profile block as defined below."', args=[d.arg(name='autoScalerProfile', type=d.T.array)]),
      withAutoScalerProfile(autoScalerProfile): { spec+: { forProvider+: { autoScalerProfile: if std.isArray(v=autoScalerProfile) then autoScalerProfile else [autoScalerProfile] } } },
      '#withAutoScalerProfileMixin':: d.fn(help='"A auto_scaler_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='autoScalerProfile', type=d.T.array)]),
      withAutoScalerProfileMixin(autoScalerProfile): { spec+: { forProvider+: { autoScalerProfile+: if std.isArray(v=autoScalerProfile) then autoScalerProfile else [autoScalerProfile] } } },
      '#withAutomaticChannelUpgrade':: d.fn(help='"The upgrade channel for this Kubernetes Cluster. Possible values are patch, rapid, node-image and stable. Omitting this field sets this value to none."', args=[d.arg(name='automaticChannelUpgrade', type=d.T.string)]),
      withAutomaticChannelUpgrade(automaticChannelUpgrade): { spec+: { forProvider+: { automaticChannelUpgrade: automaticChannelUpgrade } } },
      '#withAzureActiveDirectoryRoleBasedAccessControl':: d.fn(help='"- A azure_active_directory_role_based_access_control block as defined below."', args=[d.arg(name='azureActiveDirectoryRoleBasedAccessControl', type=d.T.array)]),
      withAzureActiveDirectoryRoleBasedAccessControl(azureActiveDirectoryRoleBasedAccessControl): { spec+: { forProvider+: { azureActiveDirectoryRoleBasedAccessControl: if std.isArray(v=azureActiveDirectoryRoleBasedAccessControl) then azureActiveDirectoryRoleBasedAccessControl else [azureActiveDirectoryRoleBasedAccessControl] } } },
      '#withAzureActiveDirectoryRoleBasedAccessControlMixin':: d.fn(help='"- A azure_active_directory_role_based_access_control block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='azureActiveDirectoryRoleBasedAccessControl', type=d.T.array)]),
      withAzureActiveDirectoryRoleBasedAccessControlMixin(azureActiveDirectoryRoleBasedAccessControl): { spec+: { forProvider+: { azureActiveDirectoryRoleBasedAccessControl+: if std.isArray(v=azureActiveDirectoryRoleBasedAccessControl) then azureActiveDirectoryRoleBasedAccessControl else [azureActiveDirectoryRoleBasedAccessControl] } } },
      '#withAzurePolicyEnabled':: d.fn(help='"Should the Azure Policy Add-On be enabled? For more details please visit Understand Azure Policy for Azure Kubernetes Service"', args=[d.arg(name='azurePolicyEnabled', type=d.T.boolean)]),
      withAzurePolicyEnabled(azurePolicyEnabled): { spec+: { forProvider+: { azurePolicyEnabled: azurePolicyEnabled } } },
      '#withDefaultNodePool':: d.fn(help='"A default_node_pool block as defined below."', args=[d.arg(name='defaultNodePool', type=d.T.array)]),
      withDefaultNodePool(defaultNodePool): { spec+: { forProvider+: { defaultNodePool: if std.isArray(v=defaultNodePool) then defaultNodePool else [defaultNodePool] } } },
      '#withDefaultNodePoolMixin':: d.fn(help='"A default_node_pool block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='defaultNodePool', type=d.T.array)]),
      withDefaultNodePoolMixin(defaultNodePool): { spec+: { forProvider+: { defaultNodePool+: if std.isArray(v=defaultNodePool) then defaultNodePool else [defaultNodePool] } } },
      '#withDiskEncryptionSetId':: d.fn(help='"The ID of the Disk Encryption Set which should be used for the Nodes and Volumes. More information can be found in the documentation."', args=[d.arg(name='diskEncryptionSetId', type=d.T.string)]),
      withDiskEncryptionSetId(diskEncryptionSetId): { spec+: { forProvider+: { diskEncryptionSetId: diskEncryptionSetId } } },
      '#withDnsPrefix':: d.fn(help='"DNS prefix specified when creating the managed cluster. Changing this forces a new resource to be created."', args=[d.arg(name='dnsPrefix', type=d.T.string)]),
      withDnsPrefix(dnsPrefix): { spec+: { forProvider+: { dnsPrefix: dnsPrefix } } },
      '#withDnsPrefixPrivateCluster':: d.fn(help='"Specifies the DNS prefix to use with private clusters. Changing this forces a new resource to be created."', args=[d.arg(name='dnsPrefixPrivateCluster', type=d.T.string)]),
      withDnsPrefixPrivateCluster(dnsPrefixPrivateCluster): { spec+: { forProvider+: { dnsPrefixPrivateCluster: dnsPrefixPrivateCluster } } },
      '#withEnablePodSecurityPolicy':: d.fn(help='', args=[d.arg(name='enablePodSecurityPolicy', type=d.T.boolean)]),
      withEnablePodSecurityPolicy(enablePodSecurityPolicy): { spec+: { forProvider+: { enablePodSecurityPolicy: enablePodSecurityPolicy } } },
      '#withHttpApplicationRoutingEnabled':: d.fn(help='"Should HTTP Application Routing be enabled?"', args=[d.arg(name='httpApplicationRoutingEnabled', type=d.T.boolean)]),
      withHttpApplicationRoutingEnabled(httpApplicationRoutingEnabled): { spec+: { forProvider+: { httpApplicationRoutingEnabled: httpApplicationRoutingEnabled } } },
      '#withHttpProxyConfig':: d.fn(help='"A http_proxy_config block as defined below."', args=[d.arg(name='httpProxyConfig', type=d.T.array)]),
      withHttpProxyConfig(httpProxyConfig): { spec+: { forProvider+: { httpProxyConfig: if std.isArray(v=httpProxyConfig) then httpProxyConfig else [httpProxyConfig] } } },
      '#withHttpProxyConfigMixin':: d.fn(help='"A http_proxy_config block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpProxyConfig', type=d.T.array)]),
      withHttpProxyConfigMixin(httpProxyConfig): { spec+: { forProvider+: { httpProxyConfig+: if std.isArray(v=httpProxyConfig) then httpProxyConfig else [httpProxyConfig] } } },
      '#withIdentity':: d.fn(help='"An identity block as defined below. One of either identity or service_principal must be specified."', args=[d.arg(name='identity', type=d.T.array)]),
      withIdentity(identity): { spec+: { forProvider+: { identity: if std.isArray(v=identity) then identity else [identity] } } },
      '#withIdentityMixin':: d.fn(help='"An identity block as defined below. One of either identity or service_principal must be specified."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='identity', type=d.T.array)]),
      withIdentityMixin(identity): { spec+: { forProvider+: { identity+: if std.isArray(v=identity) then identity else [identity] } } },
      '#withIngressApplicationGateway':: d.fn(help='"A ingress_application_gateway block as defined below."', args=[d.arg(name='ingressApplicationGateway', type=d.T.array)]),
      withIngressApplicationGateway(ingressApplicationGateway): { spec+: { forProvider+: { ingressApplicationGateway: if std.isArray(v=ingressApplicationGateway) then ingressApplicationGateway else [ingressApplicationGateway] } } },
      '#withIngressApplicationGatewayMixin':: d.fn(help='"A ingress_application_gateway block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ingressApplicationGateway', type=d.T.array)]),
      withIngressApplicationGatewayMixin(ingressApplicationGateway): { spec+: { forProvider+: { ingressApplicationGateway+: if std.isArray(v=ingressApplicationGateway) then ingressApplicationGateway else [ingressApplicationGateway] } } },
      '#withKeyVaultSecretsProvider':: d.fn(help='"A key_vault_secrets_provider block as defined below. For more details, please visit Azure Keyvault Secrets Provider for AKS."', args=[d.arg(name='keyVaultSecretsProvider', type=d.T.array)]),
      withKeyVaultSecretsProvider(keyVaultSecretsProvider): { spec+: { forProvider+: { keyVaultSecretsProvider: if std.isArray(v=keyVaultSecretsProvider) then keyVaultSecretsProvider else [keyVaultSecretsProvider] } } },
      '#withKeyVaultSecretsProviderMixin':: d.fn(help='"A key_vault_secrets_provider block as defined below. For more details, please visit Azure Keyvault Secrets Provider for AKS."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='keyVaultSecretsProvider', type=d.T.array)]),
      withKeyVaultSecretsProviderMixin(keyVaultSecretsProvider): { spec+: { forProvider+: { keyVaultSecretsProvider+: if std.isArray(v=keyVaultSecretsProvider) then keyVaultSecretsProvider else [keyVaultSecretsProvider] } } },
      '#withKubeletIdentity':: d.fn(help='"A kubelet_identity block as defined below. Changing this forces a new resource to be created."', args=[d.arg(name='kubeletIdentity', type=d.T.array)]),
      withKubeletIdentity(kubeletIdentity): { spec+: { forProvider+: { kubeletIdentity: if std.isArray(v=kubeletIdentity) then kubeletIdentity else [kubeletIdentity] } } },
      '#withKubeletIdentityMixin':: d.fn(help='"A kubelet_identity block as defined below. Changing this forces a new resource to be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='kubeletIdentity', type=d.T.array)]),
      withKubeletIdentityMixin(kubeletIdentity): { spec+: { forProvider+: { kubeletIdentity+: if std.isArray(v=kubeletIdentity) then kubeletIdentity else [kubeletIdentity] } } },
      '#withKubernetesVersion':: d.fn(help="\"Version of Kubernetes specified when creating the AKS managed cluster. If not specified, the latest recommended version will be used at provisioning time (but won't auto-upgrade).\"", args=[d.arg(name='kubernetesVersion', type=d.T.string)]),
      withKubernetesVersion(kubernetesVersion): { spec+: { forProvider+: { kubernetesVersion: kubernetesVersion } } },
      '#withLinuxProfile':: d.fn(help='"A linux_profile block as defined below."', args=[d.arg(name='linuxProfile', type=d.T.array)]),
      withLinuxProfile(linuxProfile): { spec+: { forProvider+: { linuxProfile: if std.isArray(v=linuxProfile) then linuxProfile else [linuxProfile] } } },
      '#withLinuxProfileMixin':: d.fn(help='"A linux_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='linuxProfile', type=d.T.array)]),
      withLinuxProfileMixin(linuxProfile): { spec+: { forProvider+: { linuxProfile+: if std.isArray(v=linuxProfile) then linuxProfile else [linuxProfile] } } },
      '#withLocalAccountDisabled':: d.fn(help='"- If true local accounts will be disabled. Defaults to false. See the documentation for more information."', args=[d.arg(name='localAccountDisabled', type=d.T.boolean)]),
      withLocalAccountDisabled(localAccountDisabled): { spec+: { forProvider+: { localAccountDisabled: localAccountDisabled } } },
      '#withLocation':: d.fn(help='"The location where the Managed Kubernetes Cluster should be created. Changing this forces a new resource to be created."', args=[d.arg(name='location', type=d.T.string)]),
      withLocation(location): { spec+: { forProvider+: { location: location } } },
      '#withMaintenanceWindow':: d.fn(help='"A maintenance_window block as defined below."', args=[d.arg(name='maintenanceWindow', type=d.T.array)]),
      withMaintenanceWindow(maintenanceWindow): { spec+: { forProvider+: { maintenanceWindow: if std.isArray(v=maintenanceWindow) then maintenanceWindow else [maintenanceWindow] } } },
      '#withMaintenanceWindowMixin':: d.fn(help='"A maintenance_window block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='maintenanceWindow', type=d.T.array)]),
      withMaintenanceWindowMixin(maintenanceWindow): { spec+: { forProvider+: { maintenanceWindow+: if std.isArray(v=maintenanceWindow) then maintenanceWindow else [maintenanceWindow] } } },
      '#withMicrosoftDefender':: d.fn(help='"A microsoft_defender block as defined below."', args=[d.arg(name='microsoftDefender', type=d.T.array)]),
      withMicrosoftDefender(microsoftDefender): { spec+: { forProvider+: { microsoftDefender: if std.isArray(v=microsoftDefender) then microsoftDefender else [microsoftDefender] } } },
      '#withMicrosoftDefenderMixin':: d.fn(help='"A microsoft_defender block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='microsoftDefender', type=d.T.array)]),
      withMicrosoftDefenderMixin(microsoftDefender): { spec+: { forProvider+: { microsoftDefender+: if std.isArray(v=microsoftDefender) then microsoftDefender else [microsoftDefender] } } },
      '#withNetworkProfile':: d.fn(help='"A network_profile block as defined below."', args=[d.arg(name='networkProfile', type=d.T.array)]),
      withNetworkProfile(networkProfile): { spec+: { forProvider+: { networkProfile: if std.isArray(v=networkProfile) then networkProfile else [networkProfile] } } },
      '#withNetworkProfileMixin':: d.fn(help='"A network_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='networkProfile', type=d.T.array)]),
      withNetworkProfileMixin(networkProfile): { spec+: { forProvider+: { networkProfile+: if std.isArray(v=networkProfile) then networkProfile else [networkProfile] } } },
      '#withNodeResourceGroup':: d.fn(help='"The auto-generated Resource Group which contains the resources for this Managed Kubernetes Cluster."', args=[d.arg(name='nodeResourceGroup', type=d.T.string)]),
      withNodeResourceGroup(nodeResourceGroup): { spec+: { forProvider+: { nodeResourceGroup: nodeResourceGroup } } },
      '#withOidcIssuerEnabled':: d.fn(help='"Enable or Disable the OIDC issuer URL"', args=[d.arg(name='oidcIssuerEnabled', type=d.T.boolean)]),
      withOidcIssuerEnabled(oidcIssuerEnabled): { spec+: { forProvider+: { oidcIssuerEnabled: oidcIssuerEnabled } } },
      '#withOmsAgent':: d.fn(help='"A oms_agent block as defined below."', args=[d.arg(name='omsAgent', type=d.T.array)]),
      withOmsAgent(omsAgent): { spec+: { forProvider+: { omsAgent: if std.isArray(v=omsAgent) then omsAgent else [omsAgent] } } },
      '#withOmsAgentMixin':: d.fn(help='"A oms_agent block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='omsAgent', type=d.T.array)]),
      withOmsAgentMixin(omsAgent): { spec+: { forProvider+: { omsAgent+: if std.isArray(v=omsAgent) then omsAgent else [omsAgent] } } },
      '#withOpenServiceMeshEnabled':: d.fn(help='"Is Open Service Mesh enabled? For more details, please visit Open Service Mesh for AKS."', args=[d.arg(name='openServiceMeshEnabled', type=d.T.boolean)]),
      withOpenServiceMeshEnabled(openServiceMeshEnabled): { spec+: { forProvider+: { openServiceMeshEnabled: openServiceMeshEnabled } } },
      '#withPrivateClusterEnabled':: d.fn(help='"Should this Kubernetes Cluster have its API server only exposed on internal IP addresses? This provides a Private IP Address for the Kubernetes API on the Virtual Network where the Kubernetes Cluster is located. Defaults to false. Changing this forces a new resource to be created."', args=[d.arg(name='privateClusterEnabled', type=d.T.boolean)]),
      withPrivateClusterEnabled(privateClusterEnabled): { spec+: { forProvider+: { privateClusterEnabled: privateClusterEnabled } } },
      '#withPrivateClusterPublicFqdnEnabled':: d.fn(help='"Specifies whether a Public FQDN for this Private Cluster should be added. Defaults to false."', args=[d.arg(name='privateClusterPublicFqdnEnabled', type=d.T.boolean)]),
      withPrivateClusterPublicFqdnEnabled(privateClusterPublicFqdnEnabled): { spec+: { forProvider+: { privateClusterPublicFqdnEnabled: privateClusterPublicFqdnEnabled } } },
      '#withPrivateDnsZoneId':: d.fn(help='"Either the ID of Private DNS Zone which should be delegated to this Cluster, System to have AKS manage this or None. In case of None you will need to bring your own DNS server and set up resolving, otherwise cluster will have issues after provisioning. Changing this forces a new resource to be created."', args=[d.arg(name='privateDnsZoneId', type=d.T.string)]),
      withPrivateDnsZoneId(privateDnsZoneId): { spec+: { forProvider+: { privateDnsZoneId: privateDnsZoneId } } },
      '#withPublicNetworkAccessEnabled':: d.fn(help='', args=[d.arg(name='publicNetworkAccessEnabled', type=d.T.boolean)]),
      withPublicNetworkAccessEnabled(publicNetworkAccessEnabled): { spec+: { forProvider+: { publicNetworkAccessEnabled: publicNetworkAccessEnabled } } },
      '#withResourceGroupName':: d.fn(help='"Specifies the Resource Group where the Managed Kubernetes Cluster should exist. Changing this forces a new resource to be created."', args=[d.arg(name='resourceGroupName', type=d.T.string)]),
      withResourceGroupName(resourceGroupName): { spec+: { forProvider+: { resourceGroupName: resourceGroupName } } },
      '#withRoleBasedAccessControlEnabled':: d.fn(help='"Whether Role Based Access Control for the Kubernetes Cluster should be enabled. Defaults to true. Changing this forces a new resource to be created."', args=[d.arg(name='roleBasedAccessControlEnabled', type=d.T.boolean)]),
      withRoleBasedAccessControlEnabled(roleBasedAccessControlEnabled): { spec+: { forProvider+: { roleBasedAccessControlEnabled: roleBasedAccessControlEnabled } } },
      '#withRunCommandEnabled':: d.fn(help='"Whether to enable run command for the cluster or not. Defaults to true."', args=[d.arg(name='runCommandEnabled', type=d.T.boolean)]),
      withRunCommandEnabled(runCommandEnabled): { spec+: { forProvider+: { runCommandEnabled: runCommandEnabled } } },
      '#withServicePrincipal':: d.fn(help='"A service_principal block as documented below. One of either identity or service_principal must be specified."', args=[d.arg(name='servicePrincipal', type=d.T.array)]),
      withServicePrincipal(servicePrincipal): { spec+: { forProvider+: { servicePrincipal: if std.isArray(v=servicePrincipal) then servicePrincipal else [servicePrincipal] } } },
      '#withServicePrincipalMixin':: d.fn(help='"A service_principal block as documented below. One of either identity or service_principal must be specified."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='servicePrincipal', type=d.T.array)]),
      withServicePrincipalMixin(servicePrincipal): { spec+: { forProvider+: { servicePrincipal+: if std.isArray(v=servicePrincipal) then servicePrincipal else [servicePrincipal] } } },
      '#withSkuTier':: d.fn(help='"The SKU Tier that should be used for this Kubernetes Cluster. Possible values are Free and Paid (which includes the Uptime SLA). Defaults to Free."', args=[d.arg(name='skuTier', type=d.T.string)]),
      withSkuTier(skuTier): { spec+: { forProvider+: { skuTier: skuTier } } },
      '#withTags':: d.fn(help='"A mapping of tags to assign to the resource."', args=[d.arg(name='tags', type=d.T.object)]),
      withTags(tags): { spec+: { forProvider+: { tags: tags } } },
      '#withTagsMixin':: d.fn(help='"A mapping of tags to assign to the resource."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tags', type=d.T.object)]),
      withTagsMixin(tags): { spec+: { forProvider+: { tags+: tags } } },
      '#withWindowsProfile':: d.fn(help='"A windows_profile block as defined below."', args=[d.arg(name='windowsProfile', type=d.T.array)]),
      withWindowsProfile(windowsProfile): { spec+: { forProvider+: { windowsProfile: if std.isArray(v=windowsProfile) then windowsProfile else [windowsProfile] } } },
      '#withWindowsProfileMixin':: d.fn(help='"A windows_profile block as defined below."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='windowsProfile', type=d.T.array)]),
      withWindowsProfileMixin(windowsProfile): { spec+: { forProvider+: { windowsProfile+: if std.isArray(v=windowsProfile) then windowsProfile else [windowsProfile] } } },
    },
    '#providerConfigRef':: d.obj(help='"ProviderConfigReference specifies how the provider that will be used to create, observe, update, and delete this managed resource should be configured."'),
    providerConfigRef: {
      '#policy':: d.obj(help='"Policies for referencing."'),
      policy: {
        '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
        withResolution(resolution): { spec+: { providerConfigRef+: { policy+: { resolution: resolution } } } },
        '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
        withResolve(resolve): { spec+: { providerConfigRef+: { policy+: { resolve: resolve } } } },
      },
      '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { providerConfigRef+: { name: name } } },
    },
    '#providerRef':: d.obj(help='"ProviderReference specifies the provider that will be used to create, observe, update, and delete this managed resource. Deprecated: Please use ProviderConfigReference, i.e. `providerConfigRef`"'),
    providerRef: {
      '#policy':: d.obj(help='"Policies for referencing."'),
      policy: {
        '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
        withResolution(resolution): { spec+: { providerRef+: { policy+: { resolution: resolution } } } },
        '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
        withResolve(resolve): { spec+: { providerRef+: { policy+: { resolve: resolve } } } },
      },
      '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { providerRef+: { name: name } } },
    },
    '#publishConnectionDetailsTo':: d.obj(help='"PublishConnectionDetailsTo specifies the connection secret config which contains a name, metadata and a reference to secret store config to which any connection details for this managed resource should be written. Connection details frequently include the endpoint, username, and password required to connect to the managed resource."'),
    publishConnectionDetailsTo: {
      '#configRef':: d.obj(help='"SecretStoreConfigRef specifies which secret store config should be used for this ConnectionSecret."'),
      configRef: {
        '#policy':: d.obj(help='"Policies for referencing."'),
        policy: {
          '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
          withResolution(resolution): { spec+: { publishConnectionDetailsTo+: { configRef+: { policy+: { resolution: resolution } } } } },
          '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
          withResolve(resolve): { spec+: { publishConnectionDetailsTo+: { configRef+: { policy+: { resolve: resolve } } } } },
        },
        '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { publishConnectionDetailsTo+: { configRef+: { name: name } } } },
      },
      '#metadata':: d.obj(help='"Metadata is the metadata for connection secret."'),
      metadata: {
        '#withAnnotations':: d.fn(help='"Annotations are the annotations to be added to connection secret. - For Kubernetes secrets, this will be used as \\"metadata.annotations\\". - It is up to Secret Store implementation for others store types."', args=[d.arg(name='annotations', type=d.T.object)]),
        withAnnotations(annotations): { spec+: { publishConnectionDetailsTo+: { metadata+: { annotations: annotations } } } },
        '#withAnnotationsMixin':: d.fn(help='"Annotations are the annotations to be added to connection secret. - For Kubernetes secrets, this will be used as \\"metadata.annotations\\". - It is up to Secret Store implementation for others store types."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
        withAnnotationsMixin(annotations): { spec+: { publishConnectionDetailsTo+: { metadata+: { annotations+: annotations } } } },
        '#withLabels':: d.fn(help='"Labels are the labels/tags to be added to connection secret. - For Kubernetes secrets, this will be used as \\"metadata.labels\\". - It is up to Secret Store implementation for others store types."', args=[d.arg(name='labels', type=d.T.object)]),
        withLabels(labels): { spec+: { publishConnectionDetailsTo+: { metadata+: { labels: labels } } } },
        '#withLabelsMixin':: d.fn(help='"Labels are the labels/tags to be added to connection secret. - For Kubernetes secrets, this will be used as \\"metadata.labels\\". - It is up to Secret Store implementation for others store types."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
        withLabelsMixin(labels): { spec+: { publishConnectionDetailsTo+: { metadata+: { labels+: labels } } } },
        '#withType':: d.fn(help='"Type is the SecretType for the connection secret. - Only valid for Kubernetes Secret Stores."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { spec+: { publishConnectionDetailsTo+: { metadata+: { type: type } } } },
      },
      '#withName':: d.fn(help='"Name is the name of the connection secret."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { publishConnectionDetailsTo+: { name: name } } },
    },
    '#withDeletionPolicy':: d.fn(help='"DeletionPolicy specifies what will happen to the underlying external when this managed resource is deleted - either \\"Delete\\" or \\"Orphan\\" the external resource."', args=[d.arg(name='deletionPolicy', type=d.T.string)]),
    withDeletionPolicy(deletionPolicy): { spec+: { deletionPolicy: deletionPolicy } },
    '#writeConnectionSecretToRef':: d.obj(help='"WriteConnectionSecretToReference specifies the namespace and name of a Secret to which any connection details for this managed resource should be written. Connection details frequently include the endpoint, username, and password required to connect to the managed resource. This field is planned to be replaced in a future release in favor of PublishConnectionDetailsTo. Currently, both could be set independently and connection details would be published to both without affecting each other."'),
    writeConnectionSecretToRef: {
      '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { writeConnectionSecretToRef+: { name: name } } },
      '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
      withNamespace(namespace): { spec+: { writeConnectionSecretToRef+: { namespace: namespace } } },
    },
  },
  '#mixin': 'ignore',
  mixin: self,
}
